
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>My first Project1 &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'wordcloud';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Content with notebooks" href="notebooks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Hi, this is Snow‚Äôs Program Channel ‚Äî Snowbook üìò‚ùÑÔ∏è
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="markdown.html">Markdown Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">Content with notebooks</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Wordcloud Project</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fwordcloud.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/wordcloud.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>My first Project1</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-this-project-about">What is this project aboutÔºü</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-did-i-do-it">Why did i do itÔºü</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-tools-did-i-use">What tools did I useÔºü</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-import">1. Data import</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing">2. Data processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-generating">3. Corpus Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-frequency-counting">4. Word frequency counting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wordcloud-generating">5. Wordcloud Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisation">6. Visualisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">7. Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-small-side-quest-regional-word-cloud">A small side questÔºöregional word cloudÔºÅ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">8. Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-i-learn">What did I learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-could-be-better">What could be better?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-thought">Final thought</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="my-first-project1">
<h1>My first Project1<a class="headerlink" href="#my-first-project1" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<section id="what-is-this-project-about">
<h2>What is this project aboutÔºü<a class="headerlink" href="#what-is-this-project-about" title="Link to this heading">#</a></h2>
<p>This little project started with a super practical need at work: I had access to a batch of article titles from the English Language Learning journal, and I wanted to know ‚Äî what are people actually writing about? What topics are trending? What do researchers seem to care about the most?</p>
<p>I figured a word cloud could be a quick, intuitive way to get a sense of it. More importantly, I wanted to use this as a chance to play around with Python + NLP tools on real data from my field (language education). So, this became both a content analysis project and a personal practice assignment rolled into one.</p>
</section>
<section id="why-did-i-do-it">
<h2>Why did i do itÔºü<a class="headerlink" href="#why-did-i-do-it" title="Link to this heading">#</a></h2>
<p>To be honest, I‚Äôve always felt that journal content can feel a bit‚Ä¶ abstract or scattered if you just skim through titles. But if we could pull all the titles together and extract keywords, patterns might emerge. This kind of small project can be useful for:</p>
<p>Guiding editorial direction (what themes are we already overloaded with?)
Helping contributors see what‚Äôs hot (or overdone‚Ä¶)
Just satisfying my curiosity :Ôºâ
Also, as someone learning data tools, I wanted to test-drive some basic NLP workflows: text cleaning, segmentation, frequency analysis, visualization ‚Äî all in Python.</p>
</section>
<section id="what-tools-did-i-use">
<h2>What tools did I useÔºü<a class="headerlink" href="#what-tools-did-i-use" title="Link to this heading">#</a></h2>
<p>Pretty standard setup:</p>
<p><code class="docutils literal notranslate"><span class="pre">pandas</span></code> ‚Äì for loading the Excel data (which came straight from the editorial system)
<code class="docutils literal notranslate"><span class="pre">jieba</span></code> ‚Äì for Chinese word segmentation
<code class="docutils literal notranslate"><span class="pre">counter</span></code> ‚Äì to count word frequency
<code class="docutils literal notranslate"><span class="pre">wordcloud</span></code> ‚Äì for visualizing the results
<code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> ‚Äì for showing the image
Also, I had to deal with font paths on my Mac (because Chinese in wordcloud needs a proper .ttc font).</p>
</section>
<section id="data-import">
<h2>1. Data import<a class="headerlink" href="#data-import" title="Link to this heading">#</a></h2>
<p>First things first ‚Äî I started by importing the basic libraries I needed for the project. Nothing too fancy, just the usual stack for working with Excel files and doing some text processing in Python.</p>
<p>The data itself came from my actual work ‚Äî we use an editorial system that stores manuscript info, and it luckily allows us to export everything directly as an Excel file. Super convenient! I didn‚Äôt have to clean raw HTML or scrape anything ‚Äî just hit ‚ÄúExport‚Äù and I was ready to go.</p>
<p>So I wrote this to load things up:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">jieba</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;jieba&#39;
</pre></div>
</div>
</div>
</div>
<p>Then I loaded the file like this:
„ÄêA small thing I noticed: the actual header (column names) were on the second row in the Excel file, so I had to set header=1 to read it properly. Without that, df[‚ÄòÊ†áÈ¢ò‚Äô] wouldn‚Äôt work later.„Äë</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;/Users/snowliu/Downloads/20250307170539.xls&quot;</span>

<span class="c1"># Read Excel</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s2">&quot;Á®ø‰ª∂‰ø°ÊÅØ&quot;</span><span class="p">,</span><span class="n">header</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>           Á®ø‰ª∂ÁºñÂè∑                                                 Ê†áÈ¢ò  Â≠óÊï∞ Á¨¨‰∏Ä‰ΩúËÄÖÂßìÂêç  \
0    2016040025                                    ‰æãË∞àÂçïÂÖÉÂØºËØªËØæÁöÑËØæÂ†ÇËÆæËÆ°‰∏éÂèçÊÄù NaN    ËëõÂ©∑Â©∑   
1    2023080023                                 ÁßëÊôÆÊïÖ‰∫ãËûçÂêàÈòÖËØªÊïôÂ≠¶Ë∑ØÂæÑÁöÑËÆæËÆ°‰∏éÂÆûÊñΩ NaN     ÂæêÊô∂   
2    2021070023                                     ‚ÄúÈ™®Êû∂ÊñáÊú¨‚Äù‰∏≠ÊÄùÁª¥ËÆ≠ÁªÉÁöÑÈì∫Â±ï NaN    È°æÂ∞è‰∫Æ   
3    2016010009  ÊµÖÊûêËØëÊûóÁâà„ÄäËã±ËØ≠„Äãticking timeÊùøÂùóÁöÑ ÊúâÊïàÊïôÂ≠¶‚Äî‚Äî‰ª•ËØëÊûóÁâà„ÄäËã±ËØ≠„Äã3B Unit... NaN     Ê≤àËä∏   
4    2016040034                                 È´ò‰∏≠Ëã±ËØ≠ÈòÖËØªÊïôÂ≠¶‰∏≠ÂºÄÂ±ïËØªÂêéÁª≠ÂÜôÁöÑÂ∞ùËØï NaN     Âº†Âº∫   
..          ...                                                ...  ..    ...   
160  2020040045                  Âú®ËøáÁ®ãÊÄßÊïôÂ≠¶‰∏≠ËøêÁî®StorytellingÂüπÂÖªÂ≠¶ÁîüÁöÑËæìÂá∫ÊÄßËØ≠Ë®ÄÊäÄËÉΩ NaN    ÁéãÂêõÂÖÉ   
161  2023020032       ‰ªéËØÑÂßîÁÇπËØÑÂèçËßÇÈòÖËØªÊïôÂ≠¶ÁöÑËÆ§Áü•ÊÉÖÂÜµ ‚Äî‚Äî‰ª•11-13Â±äÂÖ®ÂõΩÂàù‰∏≠Ëã±ËØ≠ËØæÂ†ÇÊïôÂ≠¶ËßÇÊë©ÂüπËÆ≠ËØæ‰∏∫‰∏™Ê°à NaN    ÈôàËÉΩÊòä   
162  2023030090  Âü∫‰∫éËã±ËØ≠Â≠¶‰π†Ê¥ªÂä®ËßÇÁöÑÂØπËØùÊïôÂ≠¶Á≠ñÁï• ‚Äî‚Äî‰ª•PEP‰∫îÂπ¥Á∫ß‰∏äÂÜåUnit 5 There is a ... NaN    ËÆ∏Áª¥Áª¥   
163  2024010133           ‰∏ªÈ¢òËØ≠Â¢ÉÂºïÈ¢Ü‰∏ãÁöÑÈ´ò‰∏≠Ëã±ËØ≠ËØ≠Ê≥ïÊïôÂ≠¶ÔºöÂ§ñÁ†îÁâà„ÄäËã±ËØ≠„ÄãÔºàÊñ∞Ê†áÂáÜÔºâÁ¨¨‰∫åÂÜåÁ¨¨ÂÖ≠ÂçïÂÖÉÊ°à‰æãÂàÜÊûê NaN     ‰∏õËïæ   
164  2023110060                                   Âú®Ëã±ËØ≠ËØæÂ†Ç‰∏≠ËßÜÈ¢ëÊïôÂ≠¶ÁöÑÊé¢ËÆ®‰∏éÂÆûË∑µ NaN    ËÆ∏Êó∂Âçá   

         Á¨¨‰∏Ä‰ΩúËÄÖÂçï‰Ωç             Á¨¨‰∏Ä‰ΩúËÄÖE-mail Á¨¨‰∫å‰ΩúËÄÖÂßìÂêç     Á¨¨‰∫å‰ΩúËÄÖÂçï‰Ωç            Á¨¨‰∫å‰ΩúËÄÖEmail  \
0    Ê±üËãèÁúÅÂçóÈÄöÁî∞ÂÆ∂ÁÇ≥‰∏≠Â≠¶       810136381@qq.com    NaN        NaN                  NaN   
1     Â§ßËøûÂ∏ÇÁ¨¨‰∏ÉÂçÅ‰πù‰∏≠Â≠¶        14910333@qq.com    Â§èÊ∫êÊ¢ì  Â§ßËøûÂ∏ÇÁ¨¨‰∫åÂçÅÂÖ´‰∏≠Â≠¶    1210572318@qq.com   
2           NaN  guxiaoliang_l@163.com    NaN        NaN                  NaN   
3     ÊòÜÂ±±Â∏ÇÁ¨¨‰∏Ä‰∏≠ÂøÉÂ∞èÂ≠¶       252139079@qq.com    NaN        NaN                  NaN   
4       ÊµôÊ±üÁúÅÂπ≥Êπñ‰∏≠Â≠¶   dashenlin123@163.com    NaN        NaN                  NaN   
..          ...                    ...    ...        ...                  ...   
160      Êù≠Â∑û‰∫ëË∞∑Â≠¶Ê†°  angela.wang@yungu.org    Ë∞¢ÊÖßËêç     Êù≠Â∑û‰∫ëË∞∑Â≠¶Ê†°  grace.xie@yungu.org   
161         NaN       eddiecnh@163.com    Â∫îÂª∫Ëä¨     ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶       zsdyjf@zjnu.cn   
162         NaN       412191495@qq.com    NaN        NaN                  NaN   
163   Â±±‰∏úÁúÅÁÉüÂè∞Á¨¨‰∏Ä‰∏≠Â≠¶       842762843@qq.com    NaN        NaN                  NaN   
164         NaN       443613995@qq.com    ÁΩóÂΩ©Áîú   ‰ΩõÂ±±Â∏ÇÂ§ñÂõΩËØ≠Â≠¶Ê†°      lct2626@126.com   

    Á¨¨‰∏â‰ΩúËÄÖÂßìÂêç  ...                 ÊäïÁ®øÊó∂Èó¥  ËÅîÁ≥ª‰∫∫                               ÈÄö‰ø°Âú∞ÂùÄ  \
0      NaN  ...   2016/4/19 15:48:12  ËëõÂ©∑Â©∑                         Ê±üËãèÁúÅÂçóÈÄöÁî∞ÂÆ∂ÁÇ≥‰∏≠Â≠¶   
1      NaN  ...    2023/8/7 15:57:04   ÂæêÊô∂        Â§ßËøûÂ∏ÇÊ≤ôÊ≤≥Âè£Âå∫Ëé≤Ëä±Â±±Ë∑Ø104Âè∑1ÂçïÂÖÉ4Ê•º1Âè∑ÊùéÊ∞∏ÂçéÂ•≥Â£´   
2      NaN  ...    2021/7/9 15:00:46  È°æÂ∞è‰∫Æ                                NaN   
3      NaN  ...   2016/1/12 19:08:49   Ê≤àËä∏            Ê±üËãèÁúÅÊòÜÂ±±Â∏ÇÈõÜË°ó178Âè∑ Á¨¨‰∏Ä‰∏≠ÂøÉÂ∞èÂ≠¶ÔºàÂàÜÈÉ®Ôºâ   
4      NaN  ...   2016/4/25 14:38:51   Âº†Âº∫                     ÊµôÊ±üÁúÅÂπ≥ÊπñÂ∏Ç‰∏úÊπñÂ§ßÈÅì831Âè∑   
..     ...  ...                  ...  ...                                ...   
160    NaN  ...   2020/4/16 22:21:19  ÁéãÂêõÂÖÉ                   Êù≠Â∑ûÂ∏ÇË•øÊπñÂå∫Êò•Áî≥Ë°ó17Âè∑‰∫ëË∞∑Â≠¶Ê†°   
161    NaN  ...    2023/2/9 18:17:14  ÈôàËÉΩÊòä            ÊµôÊ±üÁúÅÈáëÂçéÂ∏ÇÂ©∫ÂüéÂå∫ËøéÂÆæÂ§ßÈÅì688Âè∑ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶   
162    NaN  ...   2023/3/23 17:53:27  ËÆ∏Áª¥Áª¥                                NaN   
163    NaN  ...   2024/1/29 18:07:36   ‰∏õËïæ  19953516726 Â±±‰∏úÁúÅÁÉüÂè∞Â∏ÇËé±Â±±Âå∫Ââç‰∏ÉÂ§ºÂ§©ÊàêË•øÂ∑∑50-11   
164    NaN  ...  2023/11/18 15:11:11  ËÆ∏Êó∂Âçá                                NaN   

         ÈÇÆÊîøÁºñÁ†Å             Â∫ßÊú∫          ÁßªÂä®ÁîµËØù               ËÅîÁ≥ª‰∫∫Email  \
0    226001.0  0513-81100295  1.386294e+10       810136381@qq.com   
1    116021.0       84312203  1.305277e+10        14910333@qq.com   
2         NaN            NaN  1.824890e+10  guxiaoliang_l@163.com   
3    215300.0            NaN  1.525029e+10       252139079@qq.com   
4    314200.0            NaN  1.375735e+10   dashenlin123@163.com   
..        ...            ...           ...                    ...   
160       NaN            NaN  1.760581e+10  angela.wang@yungu.org   
161  321004.0            NaN  1.786063e+10       eddiecnh@163.com   
162       NaN            NaN  1.588817e+10       412191495@qq.com   
163  264001.0            NaN  1.856130e+10       842762843@qq.com   
164       NaN            NaN  1.813832e+10       443613995@qq.com   

              Áä∂ÊÄÅ Á¨¨‰∏Ä‰ΩúËÄÖORCID        Âú∞Âå∫  
0    ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN  ÂÆâÂæΩÁúÅÂÆøÂ∑ûÂ∏Ç    
1    ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN     Â∑¥‰∏≠Â∏Ç    
2    ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN      Âåó‰∫¨    
3    ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN      Âåó‰∫¨    
4    ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN      Âåó‰∫¨    
..           ...       ...       ...  
160  ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN       NaN  
161  ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN       NaN  
162  ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN       NaN  
163  ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN       NaN  
164  ÁºñËæëÈÉ®Â§ÑÁêÜÂÆåÊØï[ÂΩïÁî®]       NaN       NaN  

[165 rows x 22 columns]
</pre></div>
</div>
</div>
</div>
<p>As you can see, I just threw all the titles into a word cloud without any cleaning. Big mistake. The top words were super generic: things like ‚ÄúÁöÑ‚Äù (‚Äòs), ‚Äú‰∏é‚Äù (and), ‚Äú‰∏∫‰æã‚Äù (a case study of‚Ä¶)‚Ä¶ basically, words that show up in almost every academic title. I need to do somethingÔºÅ</p>
</section>
<section id="data-processing">
<h2>2. Data processing<a class="headerlink" href="#data-processing" title="Link to this heading">#</a></h2>
<p>So I made a custom stopword list, based on what I see over and over in educational writing. This step turned out to be the most valuable ‚Äî it made the final output much clearer.</p>
<p>Also:</p>
<p>I kept only Chinese words (filtering out symbols and punctuation)
I excluded words shorter than 2 characters
I joined all titles into one string before segmentation
This whole process reminded me that clean data beats fancy tools. Even the best word cloud won‚Äôt help if your data is full of noise.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2. Processing Chinese word segmentation</span>
<span class="k">def</span> <span class="nf">process_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># Custom stopword list: Since many meaningless words exist in these titles, they need to be removed in order to retain only the key terms.</span>
    <span class="n">stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39;ÁöÑ&#39;</span><span class="p">,</span> <span class="s1">&#39;‰∏é&#39;</span><span class="p">,</span> <span class="s1">&#39;Âèä&#39;</span><span class="p">,</span> <span class="s1">&#39;Âú®&#39;</span><span class="p">,</span> <span class="s1">&#39;Âü∫‰∫é&#39;</span><span class="p">,</span> <span class="s1">&#39;‰∏ã&#39;</span><span class="p">,</span> <span class="s1">&#39;‰∏≠&#39;</span><span class="p">,</span> <span class="s1">&#39;‰æã&#39;</span><span class="p">,</span> <span class="s1">&#39;‰ª•&#39;</span><span class="p">,</span> <span class="s1">&#39;‰∏∫‰æã&#39;</span><span class="p">,</span> <span class="s1">&#39;‚Äî‚Äî&#39;</span><span class="p">,</span> <span class="s1">&#39;ÂÆûË∑µ&#39;</span><span class="p">,</span> <span class="s1">&#39;Á†îÁ©∂&#39;</span><span class="p">,</span> <span class="s1">&#39;ÊïôÂ≠¶&#39;</span><span class="p">,</span> <span class="s1">&#39;ËÆæËÆ°&#39;</span><span class="p">,</span> <span class="s1">&#39;Á≠ñÁï•&#39;</span><span class="p">,</span> <span class="s1">&#39;Êé¢Á©∂&#39;</span><span class="p">,</span><span class="s1">&#39;ÂàõËÆæ&#39;</span><span class="p">,</span><span class="s1">&#39;Ëã±ËØ≠&#39;</span><span class="p">,</span><span class="s1">&#39;È´ò‰∏≠Ëã±ËØ≠&#39;</span><span class="p">,</span><span class="s1">&#39;ÊµÖÊûê&#39;</span><span class="p">,</span><span class="s1">&#39;ËØæ‰∏∫‰æã&#39;</span><span class="p">,</span><span class="s1">&#39;‰øÉËøõ&#39;</span><span class="p">,</span><span class="s1">&#39;Áõ∏ÁªìÂêà&#39;</span><span class="p">,</span><span class="s1">&#39;Â≠¶Áîü&#39;</span><span class="p">,</span><span class="s1">&#39;Â≠¶‰π†&#39;</span><span class="p">,</span><span class="s1">&#39;ÂüπÂÖª&#39;</span><span class="p">,</span><span class="s1">&#39;ËøêÁî®&#39;</span><span class="p">,</span><span class="s1">&#39;Êé¢Á¥¢&#39;</span><span class="p">,</span><span class="s1">&#39;ÂèäÂÖ∂&#39;</span><span class="p">,</span><span class="s1">&#39;Â∞ùËØï&#39;</span><span class="p">,</span><span class="s1">&#39;Â¶Ç‰Ωï&#39;</span><span class="p">,</span><span class="s1">&#39;ÊèêÂçá&#39;</span><span class="p">,</span><span class="s1">&#39;Êï¥Âêà&#39;</span><span class="p">,</span><span class="s1">&#39;ÊèêÈ´ò&#39;</span><span class="p">,</span><span class="s1">&#39;Âàù‰∏≠&#39;</span><span class="p">,</span><span class="s1">&#39;Âàù‰∏≠Áîü&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏ÄËäÇ&#39;</span><span class="p">,</span><span class="s1">&#39;ÂàÜÊûê&#39;</span><span class="p">,</span><span class="s1">&#39;ÊúâÊïà&#39;</span><span class="p">,</span><span class="s1">&#39;Â§öËΩÆ&#39;</span><span class="p">,</span><span class="s1">&#39;ÊïôËÇ≤&#39;</span><span class="p">,</span><span class="s1">&#39;‰æùÊâò&#39;</span><span class="p">,</span><span class="s1">&#39;ÈÄöËøá&#39;</span><span class="p">,</span><span class="s1">&#39;Â∞èÂ≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;Âàù‰∏≠Ëã±ËØ≠&#39;</span><span class="p">,</span><span class="s1">&#39;È´ò‰∏≠Áîü&#39;</span><span class="p">,</span><span class="s1">&#39;ÂºÄÂ±ï&#39;</span><span class="p">,</span><span class="s1">&#39;ÊåáÂêë&#39;</span><span class="p">,</span><span class="s1">&#39;È´ò‰∏≠&#39;</span><span class="p">,</span><span class="s1">&#39;ÁªìÂêà&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏≠Â≠¶Ëã±ËØ≠&#39;</span><span class="p">,</span><span class="s1">&#39;ÈóÆÈ¢ò&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏∫‰æã&#39;</span><span class="p">,</span><span class="s1">&#39;‰æãË∞à&#39;</span><span class="p">,</span><span class="s1">&#39;ËØëÊûó&#39;</span><span class="p">,</span><span class="s1">&#39;ËûçÂêà&#39;</span><span class="p">,</span><span class="s1">&#39;ÈòÖËØªÊïôÂ≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏≠Â∞è&#39;</span><span class="p">])</span>
    
    <span class="c1"># Use Jieba for word segmentation</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
    
    <span class="c1"># Filter out stopwords and non-Chinese characters</span>
    <span class="n">filtered</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> 
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> 
           <span class="s1">&#39;</span><span class="se">\u4e00</span><span class="s1">&#39;</span> <span class="o">&lt;=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="s1">&#39;</span><span class="se">\u9fff</span><span class="s1">&#39;</span> <span class="ow">and</span> 
           <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="corpus-generating">
<h2>3. Corpus Generating<a class="headerlink" href="#corpus-generating" title="Link to this heading">#</a></h2>
<p>In this step, I can generate a corpus from the title keywords after word segmentation and filtering.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate corpus</span>
<span class="n">all_titles</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Ê†áÈ¢ò&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">())</span>
<span class="n">processed_text</span> <span class="o">=</span> <span class="n">process_text</span><span class="p">(</span><span class="n">all_titles</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then I print the filtered keywords.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">processed_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ÂçïÂÖÉ ÂØºËØª ËØæÂ†Ç ÂèçÊÄù ÁßëÊôÆ ÊïÖ‰∫ã Ë∑ØÂæÑ ÂÆûÊñΩ È™®Êû∂ ÊñáÊú¨ ÊÄùÁª¥ ËÆ≠ÁªÉ Èì∫Â±ï ÊùøÂùó ÂêéÁª≠ Ë∫´‰∏¥ÂÖ∂Â¢É ‰πêÂú®ÂÖ∂‰∏≠ ËØ≠ÁØá ÊÑèËØÜ ÂàõÁºñ ÂØπËØù ËÉΩÂäõ Ë°îÊé• Ëá™ÁÑ∂ ÊãºËØª ÂõΩÈôÖÈü≥Ê†á ËØ≠Èü≥ ÊïôÂ≠¶Á≠ñÁï• ÂàùÊé¢ Ëß£Á†Å ÁªòÊú¨ ÊâπÊ≥® ÈòÖËØª Á¥†ÂÖª ÂçïÂÖÉ Ê¥ªÂä® Ê†áÈ¢ò ‰∏Ä‰ΩìÂåñ ÊàèÂâß ‰ª≤Â§èÂ§ú ‰πãÊ¢¶ ÈÄÜÂêë ÂçïÂÖÉ ÂÜô‰Ωú ÊïôÁâà ÂÖ´Âπ¥Á∫ß ‰∏ãÂÜå ÈÄÜÂêë ÁêÜÂøµ ÊåáÂØº ÂØπËØù Ëã±ÂõΩ Ê∞ëÊóè Ë∫´‰ªΩ Á§æ‰ºö ÊñáÂåñ ËßÜÈòô Áª¥Â§öÂà©‰∫ö Ê∑ëÂ•≥ ÂÖ∏ËåÉ Ê®°Âûã ÊïôÊùê È°πÁõÆ ‰∫∫ÊïôÁâà ÈÄâ‰øÆ ÊùøÂùó ÊîπÂèò ÊïôÂ∏à ËØùËØ≠ ËØæÂ†Ç ÂèÇ‰∏éÂ∫¶ Ë°åÂä® ‰øÆÊîπ ‰∏âÊñ∞ ËÉåÊôØ ‰∏≠Â∞èÂ≠¶ ÊïôÂ∏à ÊñáÂ≠¶ Á¥†ÂÖª Ë∑ØÂæÑ Ëã±ËØ≠ÊïôÊùê ÂØπËØù ÈÉ®ÂàÜ ËØçÂùó ÁªìÊûÑÂåñ Áü•ËØÜ ‰Ωú‰∏∫ ‰∏ªÁ∫ø ÂçïÂÖÉ Êï¥‰Ωì Ë∑ØÂæÑ ‰ª•Â§ñ Á†îÁâà Âàù‰∫å ËÆæËÆ°ËØ¥Êòé ÊûÑÂª∫ ‰ªªÂä° ÁõÆÊ†á ÂêàÁêÜ ÂÆö‰Ωç ‰æãÊûê ÊñáÂ≠¶ ËØæÂ§ñÈòÖËØª ÊñáÊú¨ Ëß£ËØª ‰ª•ÂÜô ‰øÉËØª ÁêÜÂøµ Êä•Âàä ÊâπÊ≥® ÈòÖËØª ËåÉÊñá ÂÜô‰Ωú ÊÑè‰πâ Â∫îÁî® ËØ≠ÊñôÂ∫ì ÊäÄÊúØ ËØªÂÜôËÉΩÂäõ Â§öÁª¥ ÈòÖËØª ÊïÖ‰∫ã Â§±Ë∏™ ÁùÄÁúº Êï¥‰Ωì ‰ºòÂåñ Âê¨Ââç Ê¥ªÂä® ÂåóÂ∏àÂ§ß Âê¨ËØ¥ ÁõÆÊ†á ËÆæÂÆö ÂçïÂÖÉ Êï¥‰Ωì ‰Ωú‰∏ö ËøõÈò∂ ÈòÖËØª ÂÜô‰Ωú ÂçèÂêå ÂèëÂ±ï Áæ§Êñá ËØªÂÜô ËØæÂ†Ç ÁªòÊú¨ ËØªÂÜô ÂèåÂêë ËûçÈÄö ÊïôÂ≠¶Á≠ñÁï• Â∞èÂàù Ë°îÊé• Áé∞Áä∂ ÊÄùËÄÉ ‰ª•Âêå ÂºÇÊûÑ ÈòÖËØª ÊãìÂ±ï ‰∫ßÂá∫ ÂØºÂêë ËßÜÂüü ËØªÂÜô ÂØπÁ≠ñ Âü∫Êú¨ ÁßÅ‰∏ã ÂØπËØù Â∫îÂØπ ÊñπÂºè ÂØπËØù Âè£ËØë ËØëÂëò ËßíËâ≤ Ë°®Áé∞ ÁúºÁ•û ‰∫íÂä® ËΩ¨Êç¢ ‰∏§È°π ÊåáÊ†á Ê°à‰æã Á≤æËÆæ ÊûÑÂª∫ È´òÊïà ËØæÂ†Ç ÁâõÊ¥• ‰∏äÊµ∑ ÊïÖ‰∫ã ÊùøÂùó ÂèåÈáç ËßíËâ≤ ÈòÖËØª Ê®°Âºè ÊïÖ‰∫ã ÂàõÊñ∞ Â∫îÁî® ÂÖ´Âπ¥Á∫ß ÂÖ∏ËåÉ ÊïÖ‰∫ã ÈòÖËØªËØæ Ê†πÊçÆ Êñ∞Èóª ËØ≠ÁØá ÁâπÁÇπ ÊåáÂØº Êñ∞Èóª Âê¨ËØ¥ Âæ™ÁéØÂºè ËØæÂ†Ç Ê¥ªÂä® Á§æ‰ºö‰∏ª‰πâ Ê†∏ÂøÉ ‰ª∑ÂÄºËßÇ ÂÜô‰Ωú ÂëΩÈ¢ò Ê∏óÈÄè ËøáÁ®ã ÂèñÂêë Âê¨Âäõ ÂÖ¨ÂºÄËØæ ÁâáÊÆµ ËØÑÊûê ÊÄùËÄÉ Ê∑±Â±Ç ÊñáÊú¨ Ëß£ËØª ‰∏≠Â≠¶Áîü ÊÄùÁª¥ËÉΩÂäõ Á†îÁâà Ê†áÂáÜ ‰∫îÂπ¥Á∫ß ‰∏äÂÜå ‰æãËÆÆ ËØæÂ†ÇÊïôÂ≠¶ ÊÄùÁª¥ ÁÅµÊ¥ªÊÄß ÂÜô‰Ωú ÊïôÂ≠¶Á≠ñÁï• Ê†°ÈôÖ Âçè‰Ωú ÊïôÁ†î Ê®°Âºè Ê¨ßÊ¥≤ ÊàëÂõΩ Â§ñËØ≠ ÊîπÈù© Ê≠£Âºè ËÅöÁÑ¶ ‰∏ªÈ¢ò ËØ≠Â¢É ÈòÖËØª ÊïôÂ≠¶Ê®°Âºè Â∑ßÂÄü ËØ≠Ê≥ï ËØæÂ†Ç Âä©Êé® ÊÄùÁª¥ ÂèëÂ±ï ÈòÖËØª ËØæÂ†Ç ÁßØÊûÅ ÂèçÈ¶à ËÆ§Áü• ÊîØÊû∂ ÂäüËÉΩ ÁâπÂæÅ ËßÜÂê¨ ËØæ‰∏≠ ÊâπÂà§ÊÄß ÊÄùÁª¥ È¢ò‰∏∫ ÂÖ´Âπ¥Á∫ß ËßÜÂê¨ Âõ¥Áªï ËØùÈ¢ò ÊÉÖÂ¢É ÊøÄÂèë ÊÄùÁª¥ ËøáÁ®ã ÂÜô‰Ωú È´òÈò∂ ÊÄùÁª¥ ÈòÖËØªËØæ ËØªÂêé Ê¥ªÂä® ‰∏ªÈ¢ò ÊÑè‰πâ Â§çËø∞ ÂÜô‰ΩúÊ∞¥Âπ≥ Â∞èÂ≠¶Áîü ÂàõÊñ∞ Á≤æÁ•û ÁªòÊú¨ ÈòÖËØª ÊÄùËÄÉ ËØ≠ÁØá ÁªÑÁªá Ê®°Âºè ËØ¥ÊòéÊñá ÊñáÊú¨ Ëß£ÊûÑ Â§öÂÖÉ ÊîØÊû∂ ËØóÊ≠å ÂÆûÊïà ‰ªéÁôΩ Áâ°‰∏π‰∫≠ Ëã±ËØëÊú¨ ‰∏≠ÂõΩ Âè§ÂÖ∏ ÊàèÂâß Ëã±ËØë Ë°®ÊºîÊÄß Ê†∏ÂøÉ Á¥†ÂÖª ËØ¥ÊòéÊñá ËÉåËØµ ‰∏Ä‰ΩìÂåñ Â∏àÁîü ÂÖ±ËØª Êï¥Êú¨‰π¶ ÈòÖËØª ÊåáÂØº ËÉΩÂäõ Âê¨ËØ¥ ËØÑ‰ª∑ ÂÆûÊñΩ ÂçïÂÖÉ ‰Ωú‰∏ö ÂáèËΩª ‰Ωú‰∏öË¥üÊãÖ Ë°åÂä® ‰∫∫ÊïôÁâà ‰∏ÄÂπ¥Á∫ß Ëµ∑ÁÇπ ‰∫î‰∏ä ÂçïÂÖÉ ‰Ωú‰∏ö ÂçïÂÖÉ Êï¥‰Ωì ËßÜËßí ÂÜô‰Ωú ÂØπËØù È¢ÑÊµã ÊäÄÂ∑ß Ê†∏ÂøÉ Á¥†ÂÖª ÂØºÂêë ÊñáÂ≠¶ ËØ≠ÁØá ÁªÜËäÇ ÊèèÂÜô ÊïôÂ≠¶Á≠ñÁï• Ê∑±Â∫¶ ÂêéÁª≠ ËØæÂ†ÇÊïôÂ≠¶ ËØÑ‰ª∑ Ê¥ªÂä® ÂÆûÊñΩ ÁªòÊú¨ ÊïôÊùê ÊñáÂåñ ÊÑèËØÜ ËøûÊé• ËßÜËßí ËØªÂÜô ÂÆûÊñΩ Ë∑ØÂæÑ Ë¥ùÂ§öËä¨ Èªë‰∫∫ ÁúãÁ∫≥‰∏Å ÊààËø™Èªò ÊôöÊúü È£éÊ†º ÂçïÂÖÉ ‰∏ªÈ¢ò ÊÑè‰πâ ÁªòÊú¨ ÂàùÊé¢ ‰∏ÄÂõæ Â§öÁî® Ëã±ËØ≠ÊïôÊùê ÂõæÁâá ËµÑÊ∫ê Âà©Áî® ÂÆûÊïà ‰∏ªÈ¢ò ÊÑè‰πâ ÁªòÊú¨ Â§öÁª¥ ÈòÖËØª Á¨¨‰∏ÉÁ∫ß ‰∏ÄËØæ ÁúüÁêÜ Á®≥ÂÆöÊÄß Á∫¶Áø∞ÈÄä ËééËØÑ ÁêÜÊÄß Âê¨ÂÜô ÈáçÊûÑ Âê¨ËØ¥ ËØæ‰∏≠ ÊûÑÂª∫ ‰∏Ä‰Ωì ËØóÊ≠å Ê®°Âûã Êñá‰∏≠ ÊÄùÂõæ Â§ñÁ†î ÁâàÂõæ ÊñáÂºè ÊïôÊùê ‰∏ªÈ¢ò ËØ≠Â¢É Ëã±ËØ≠ËØçÊ±á ÂøÉÊô∫ ÂõæÊ≥ï ‰ªøÂÜô ÁªÉ‰π† Â∫îÁî® Êñ∞ËØæÊ†á Ê∑±Âú≥ ÁâõÊ¥• ‰∏âÂπ¥Á∫ß ÂõæÁâá ‰ø°ÊÅØ ÂÜçÊûÑ ÊñáÊú¨ ÊïôÂ≠¶Á≠ñÁï• Ëã±Êñá ÁªòÊú¨ ÈòÖËØª ËØæÂ†Ç ÊèêÈóÆ ËøûÁéØ ÊîπËøõ ‰∫§‰∫í ÂçèÂêå ÂÜô‰Ωú Ê≠•Ê≥ï Ëã±ËØ≠ÊïôÂ≠¶ Â∫îÁî® ÂçïÂÖÉ Êï¥‰Ωì ÊïôÊùê ÊèíÂõæ ‰∫îÁßç ‰ΩøÁî® ÊñπÊ≥ï ÂÖ≥‰∫é ÈòÖËØªËØæ ÂºÄÊîæÊÄß ÂèÇ‰∏éÂ∫¶ Ë°åÂä® ÈáçÊñ∞ ‰∏ÄÈÅç ‰∏≠Ë¶Å Âº∫Âåñ ÈòÖËØª Ê∏óÈÄè ÊÑèËØÜ ‰ºöËØù ËØ≠Ë®Ä ÊâøËΩΩ ÊµÖË∞à Ëã±ËØ≠ËØæÂ†Ç Á´•ËØùÊïÖ‰∫ã ËøõË°å ÊÄùÁª¥ ËÆ≠ÁªÉ ‰∏ÄÂ†Ç ËØæÈ¢ò ÂÆûÈ™åËØæ ÊïôÁ†î ÊãìÂ±ï Ê∏†ÈÅì ÂÖ≠Âπ¥Á∫ß ÂÜô‰ΩúËÉΩÂäõ ÊÄùÁª¥ ÂØºÂõæ Ëã±Êñá Â∞èËØ¥ ÊÄùÁª¥ ÂìÅË¥® Êé¢‰æã ÁêÜËÆ∫ È´òÂπ¥Á∫ß ÊèêÈóÆ ËØæÂûã ÂèØËßÜÂåñ ËØäÊñ≠ ÊµãËØÑ Âü∫Á°Ä ÊïôÂ∏à ËØæÂ†Ç ËØÑ‰ª∑ Á¥†ÂÖª ÂèëÂ±ï ‰∏™Ê°àÁ†îÁ©∂ ËØäÊñ≠ ‰øÉËØÑ ‰ª•ËØÑ ‰øÉÊïô Ëã±ËØ≠ËØæÂ†Ç Âª∫Á´ã ËØÑ‰ª∑ Ê®°Âºè ÊàèÂâß ÊñáÂ≠¶ ÈòÖËØª ËØæÂ†Ç ËØ≠ÁØá ËØ≠Â¢É Ëã±ËØ≠ËØ≠Ê≥ï Â§ç‰π† ‰∏âÂ∑ß ÂÆûÊñΩ ÂæÆËØ≠ ÈòÖËØª ËØ≠Ë®Ä Áü•ËØÜ ÂçïÂÖÉ ‰∏ªÈ¢ò ÊÑè‰πâ ‰∫íÂä® ÂçèÂêåÊïàÂ∫î ÂêéÁª≠ Â≠¶Áßë Ê†∏ÂøÉ Á¥†ÂÖª Ê¥ªÂä® Êé¢Êûê Âê¨ËÆ∞ Â§çËø∞ Âê¨ËØ¥ ËÉΩÂäõ ÊÄùËÄÉ ‰ø°ÊÅØÊäÄÊúØ ÊîØÊåÅ ‰π†Êú¨ ÂàùÊé¢ Âü∫Êú¨ È´ò‰∏≠Â≠¶Áîü Â≠¶Áßë ÊÄùÁª¥ ÂìÅË¥® ÁªÜËØª Ê≥õËØª Â§çÊùÇ ÊñáÊú¨ ÈòÖËØª Êé®Ëøõ ÂêéÁª≠ Âê¨Âäõ ÊµãËØÑ ÂèçÊã® Âê¨Âäõ Ë∑ØÂæÑ ÁªòÊú¨ ÈòÖËØª ÊãºËØª ËØæ‰∏≠ ‰∫îÂπ¥Á∫ß ‰∏äÂÜå ËØ≠ÊñôÂ∫ì ËØçËØ≠ Êê≠ÈÖç Â∫îÁî® ÂêØÁ§∫ ËÅîÊé• È°πÁõÆ Ê¥ªÂä® ÁîüÊ¥ªÂÆûË∑µ ËØæÂûã Â∫îÁî®Êñá ÈòÖËØª ËØæÂ†Ç ÂèçÊÄù Âà©Áî® ÊïôÊùê ÊèíÂõæ ‰ºòÂåñ ËØ≠ÁØá ‰æ¶Êé¢ Á†¥Ê°à ÊÉÖÂ¢É ÂàõÊñ∞ ÊñáÂ≠¶ ËµèËØª ÊÄùË∑Ø ÁßëÊôÆ ËØ¥ÊòéÊñá ÊÄùÁª¥ ËØªÂÜô ÁªºÂêàËØæ Êû∂ÊûÑ ÊãºÂõæ ÈòÖËØª ÁßëÊôÆ ÁªòÊú¨ Â∫îÁî® ÁªòÊú¨ ÁªºÂêà ËßÜËßí Ë∑ØÂæÑ Êé¢Êûê Áã¨ÁôΩ ÊñáÊú¨ Âê¨ËØ¥ ÂèçÊÄù ËØ≠ÁØá ‰∏ªÈ¢ò ÊÑè‰πâ ËØªÂêé ËØçÊ±á Â∑©Âõ∫ Ê¥ªÂä® Áé∞Êúâ ËÆ§Áü• Âü∫Á°Ä ÂèëÂ±ï ËØ≠Ë®Ä ËÉΩÂäõ ÊÄùÁª¥ ÂìÅË¥® ÊñáÂ≠¶ ËØ≠ÁØá ÂêéÁª≠ Ê¥ªÂä® Âê¨Âäõ Â§öÈ°π ÂåπÈÖç ‰∏≠Â∞èÂ≠¶Áîü ÊÄùËæ® ËÉΩÂäõ ‰ª∑ÂÄº Êé¢Êûê ËÅöÁÑ¶ ËÆ≠ÁªÉ ÊãìÂ±ï Ëá™Â≠¶ Ê¥ªÂä® ÊåáÂØº È°πÁõÆ Á£®ËØæ ÁªèÂéÜ Â∞èËØ¥ ÊñáÊú¨ ÂêéÁª≠ ÂÜôÂæÆ ÂâßÊú¨ Â§öÁª¥ ÈòÖËØª ËØªÂÜô ËØ≠Ë®Ä ÊÄùÁª¥ ÂêåÊ≠• ËΩ¨Âåñ ÊïôÂ≠¶Á≠ñÁï• Ëã±ËØ≠ËØçÊ±á Â≠¶‰π†Á≠ñÁï• Ë∑ØÂæÑ ÂΩ¢Êàê ËØÑ‰ª∑ ‰ªªÂä° ËßÜÂüü ËØªÂÜôËÉΩÂäõ Â§öÁª¥ ÈòÖËØª ËôöÊûÑ ÊñáÊú¨ Â∏àÁîü Âêà‰Ωú ËØÑ‰ª∑ ÂêéÁª≠ È¢Ñ‰π† ‰∏âÂπ¥Á∫ß Â≠¶Âõ∞Áîü ËΩ¨Âåñ Ë°åÂä® Ê∑∑ÂêàÂºè Ëã±ËØ≠ËØ≠Ê≥ï ‰ª•ËØª ‰øÉÂÜô ‰ª•ÂÜô ‰øÉËØª È©±Âä® ÂéüÁâà‰π¶ ËØªÂÜô Êñ∞ËØæÊ†á ÁêÜÂøµ ‰∏âÂπ¥Á∫ß ÂØπËØù ÊïôÂ≠¶Ê®°Âºè ÂÜçÊûÑ ‰ª•‰∫¨Áâà ÂÖ∏ËåÉ Â∞èËØ¥ ËΩΩ‰Ωì ‰ª•ËØª ‰øÉÂÜô ÂêéÁª≠ ‰∫∫ÊïôÁâà Ëã±ËØ≠ÊïôÊùê ËØªÂêé ‰ªøÂÜô Ë°îÊé• ÈáçË¶Å ÂÖÉÁ¥† ËØäÊñ≠ ÊµãËØÑ ÂêéÁª≠ ÊîØÊû∂ Êê≠Âª∫ ËØæ‰æã ÂèÇ‰∏é ËÉåËØµ Ê®°Âºè Âèô‰∫ã ËÉåËØµ ‰∏ìÈ¢ò ËØ≠ÁØá ËÉåËØµ Ê¥ªÂä® ËØ≠Ë®Ä ËæìÂá∫ Ë¥®Èáè ÊñáÂ≠¶‰ΩúÂìÅ ‰∏âÁª¥ ËøõÈò∂ Áª≠ÂÜô Ê†∑Âºè ÂÖ∏ËåÉ ‰∏ªÈ¢ò Áü•ËØÜ ÁªìÊûÑÂåñ Ëá™‰∏ª Ê†∏ÂøÉ Á¥†ÂÖª ËÉåÊôØ ÊÄùÁª¥ ÂìÅË¥® ÂèëÂ±ï ÁªòÊú¨ Ëã±ËØ≠ÊïôÂ≠¶ ÁõÆÊ†á ÂØπÁ≠ñ ÂÜô‰Ωú Ëá™Êàë ËØÑ‰ª∑ Ëã±ËØ≠ÊïôÂ≠¶ ‰øÉÊÄù Ë∑ØÂæÑ Ê®°ÊÄÅ ËØ≠ÁØá ‰ªªÂä° Ëã±ËØ≠ËØæÂ†Ç Ëæ©ËÆ∫ ËØ≠Ë®Ä ËÉΩÂäõ ÊÄùÁª¥ ÂìÅË¥® ÂçèÂêå ÂèëÂ±ï ÂàùÊé¢ ‰∫∫ÊïôÁâà ÂÖ´Âπ¥Á∫ß ‰∏ãÂÜå ÈòÖËØªËØæ Â∞èËØ¥ ÊÑèËØÜÊµÅ ËØ≠Ë®Ä ÁøªËØë Â∞§Âà©Ë•øÊñØ ÂàòËØë ÁÆ°Á™• Á∫¢Ê•ºÊ¢¶ Ê®°Á≥ä ÈôêÂà∂ Ëã±ËØë ËøáÁ®ã ÂÜô‰Ωú ÂèëÂ±ï ÂàõÈÄ†ÊÄß ÊÄùÁª¥ËÉΩÂäõ Âêå‰º¥ ‰∫íËØÑ ‰∫íËØÑ ÈáèË°® ÂÜô‰Ωú ‰∏ªË¶Å Ëß£ÂÜ≥ ‰∏ªÈ¢ò ËØ≠Â¢É Ëã±ËØ≠ËØçÊ±á ÈôÑÂ∏¶ ÊïôÂ≠¶Á≠ñÁï• Ê¥ªÂä® ÁªºÂêà ÊäÄËÉΩ ÊùøÂùó ÊïôÂ≠¶Ê¥ªÂä® ÂÖ≥ËÅîÊÄß ÊÄùÁª¥ ÂèØËßÜÂåñ Â∑•ÂÖ∑ Êï¥Êú¨‰π¶ ËØªÂêé Ê¥ªÂä® ÈùíÂ∞ëÂπ¥ ÊàêÈïø Ëã±Êñá Â∞èËØ¥ ÂÆóÊïô ‰∏ñÁïåËßÇ Âè§ÂÖ∏ ÂÆ°Áæé ÂéüÂàô Ëí≤Êüè ÊñáÂ≠¶ÊâπËØÑ ÊÄùÊÉ≥ Ê¥ªÂä® ÂçïÂÖÉ ËØçÊ±á ‰Ωú‰∏ö ‰ªªÂä° È©±Âä® ÈòÖËØª Â§çËø∞ ËÉΩÂäõ ËØªËÄÖ ÂâßÂú∫ ‰∏≠Â≠¶Áîü ÊúóËØª ËÉΩÂäõ ÊúóËØª ‰ΩìÈ™å ‰∫íËÅîÁΩë Êó∂‰ª£ Ëé∑Âèñ ËØçÊ±áÂ≠¶ Áü•ËØÜ Êñ∞ÈÄîÂæÑ Âú®Á∫ø ËØçÂÖ∏ ‰∏≠Â∞èÂ≠¶ Ëã±ËØ≠ÊïôÂ≠¶ ÂêØÁ§∫ ÊÉÖÂ¢É È´òÈò∂ ÊÄùÁª¥ ÈòÖËØªËØæ ËØªÂêé Ê¥ªÂä® ÂçïÂÖÉ Êï¥‰Ωì ËßÜËßí ÂÜô‰Ωú Ê¥ªÂä® Ê∑±Â∫¶ ËØªÂÜô ËøáÁ®ã ËæìÂá∫ ËØ≠Ë®Ä ÊäÄËÉΩ ËØÑÂßî ÁÇπËØÑ ÂèçËßÇ ËÆ§Áü• ÊÉÖÂÜµ ÂÖ®ÂõΩ ËØæÂ†ÇÊïôÂ≠¶ ËßÇÊë© ÂüπËÆ≠ ËØæ‰∏∫ ‰∏™Ê°à Ê¥ªÂä® ÂØπËØù ÊïôÂ≠¶Á≠ñÁï• ‰∫îÂπ¥Á∫ß ‰∏äÂÜå ‰∏ªÈ¢ò ËØ≠Â¢É ÂºïÈ¢Ü Ëã±ËØ≠ËØ≠Ê≥ï Á†îÁâà Ê†áÂáÜ Á¨¨‰∫åÂÜå Á¨¨ÂÖ≠ ÂçïÂÖÉ Ê°à‰æã Ëã±ËØ≠ËØæÂ†Ç ËßÜÈ¢ë Êé¢ËÆ®
</pre></div>
</div>
</div>
</div>
<p>But even after applying the stopwords, I found that the results still had a few noisy or meaningless terms. So I manually removed a few more ‚Äî kind of a second-round cleanup.</p>
</section>
<section id="word-frequency-counting">
<h2>4. Word frequency counting<a class="headerlink" href="#word-frequency-counting" title="Link to this heading">#</a></h2>
<p>Let‚Äôs count the word frequency.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count the keyword frequency</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">processed_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="wordcloud-generating">
<h2>5. Wordcloud Generating<a class="headerlink" href="#wordcloud-generating" title="Link to this heading">#</a></h2>
<p>Custom the wordcloud picture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate wordcloud</span>
<span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span>
    <span class="n">font_path</span><span class="o">=</span><span class="s2">&quot;/System/Library/Fonts/Supplemental/Songti.ttc&quot;</span><span class="p">,</span>  
    <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>  <span class="c1"># background color</span>
    <span class="n">max_words</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>            <span class="c1"># The maximum number of words displayed</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>    <span class="c1"># The size of picture</span>
    <span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span>         <span class="c1"># color matching</span>
<span class="p">)</span>

<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">wc</span><span class="o">.</span><span class="n">generate_from_frequencies</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualisation">
<h2>6. Visualisation<a class="headerlink" href="#visualisation" title="Link to this heading">#</a></h2>
<p>Use matlotlib generate a picture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualise the wordcloud and import the picture.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">wordcloud</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s1">&#39;english_learning_wordcloud.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a12c789f2094a3c31a3a3d45d07b939395aaee4944a7f8610d9f0abd2bb781b7.png" src="_images/a12c789f2094a3c31a3a3d45d07b939395aaee4944a7f8610d9f0abd2bb781b7.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;wordcloud.wordcloud.WordCloud at 0x16fed7e90&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="analysis">
<h2>7. Analysis<a class="headerlink" href="#analysis" title="Link to this heading">#</a></h2>
<p>The word cloud generated from manuscript titles in English Language Learning highlights a clear thematic concentration on reading, thinking, writing, and classroom activity design. The most prominent term is ÈòÖËØª (reading), indicating that reading instruction is a central concern of the journal. This focus is further supported by related terms such as ËØ≠ÁØá (text), ËØªÂÜô (reading-writing), and ËØªÂêéÂÜô (post-reading writing), suggesting an integrated approach to reading and writing in the language learning process.</p>
<p>ÊÄùÁª¥ (thinking) appears frequently, reflecting an emphasis on the cultivation of critical and reflective thinking skills. This focus aligns with broader educational goals that aim to develop students‚Äô cognitive abilities and strategic learning approaches. Terms like Á≠ñÁï• (strategy), Ë∑ØÂæÑ (pathway), and ÂèçÊÄù (reflection) further indicate an interest in thinking-driven teaching models and learning processes.</p>
<p>ÂÜô‰Ωú (writing) is another dominant theme, pointing to the importance of writing pedagogy and its integration with reading activities. The recurrence of terms such as ‰ªªÂä° (task), ËæìÂá∫ (output), and ‰ΩúÊñá (composition) suggests a task-based orientation that emphasizes writing as both a learning objective and a method for language output.</p>
<p>Classroom practice is a significant dimension of the submitted manuscripts, as seen in keywords like ËØæÂ†Ç (classroom), Ê¥ªÂä® (activity), ÂÆûÊñΩ (implementation), and ÊïôÂ≠¶Á≠ñÁï• (teaching strategies). These terms imply a strong emphasis on practical teaching, lesson design, and classroom engagement. Additional words such as ÂçïÂÖÉ (unit), È°πÁõÆ (project), and Ê®°Âºè (model) point to structural considerations in curriculum design and innovative instructional formats.</p>
<p>Overall, the thematic focus of the journal‚Äôs manuscripts reflects a strong commitment to reading-centered instruction, the integration of thinking and writing, and the development of effective and engaging classroom practices.</p>
</section>
<section id="a-small-side-quest-regional-word-cloud">
<h2>A small side questÔºöregional word cloudÔºÅ<a class="headerlink" href="#a-small-side-quest-regional-word-cloud" title="Link to this heading">#</a></h2>
<p>While I was working on the title-based word cloud, I got curious ‚Äî what if I looked at author affiliations or regions instead? Maybe that would reveal something interesting too.</p>
<p>So I made a small tweak in the code to switch the data source: instead of grabbing all the titles, I pulled in the ‚Äú‰ΩúËÄÖÂú∞Âå∫‚Äù (author region) column and built a new corpus from that.</p>
<p>Of course, this required updating the stopword list again. This time I removed a different set of high-frequency but unhelpful words like ‚ÄúÁúÅ‚Äù (province), ‚ÄúÂ∏Ç‚Äù (city), ‚ÄúÂ§ßÂ≠¶‚Äù (university), and similar generic location terms. I also filtered out empty entries and single-character tokens to keep things clean.</p>
<p>Then I used the same pipeline ‚Äî segmentation, filtering, counting, word cloud generation ‚Äî and it worked nicely.</p>
<p>The result? A word cloud that visually shows which regions or institutions appear most frequently. Not exactly deep analysis, but it was a fun side experiment and a good reminder that once the basic pipeline is built, you can reuse it flexibly for different types of text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;/Users/snowliu/Downloads/20250307170539.xls&quot;</span>

<span class="c1"># read Excel</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s2">&quot;Á®ø‰ª∂‰ø°ÊÅØ&quot;</span><span class="p">,</span><span class="n">header</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>


<span class="c1"># 2. Processing Chinese word segmentation</span>
<span class="k">def</span> <span class="nf">process_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># Custom stopword list</span>
    <span class="n">stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39;Â∏Ç&#39;</span><span class="p">,</span> <span class="s1">&#39;ÁúÅ&#39;</span><span class="p">,</span> <span class="s1">&#39;Âå∫&#39;</span><span class="p">,</span> <span class="s1">&#39;ÊïôËÇ≤&#39;</span><span class="p">,</span> <span class="s1">&#39;ÂèëÂ±ï&#39;</span><span class="p">,</span> <span class="s1">&#39;Á¨¨&#39;</span><span class="p">,</span> <span class="s1">&#39;‰∏Ä&#39;</span><span class="p">,</span> <span class="s1">&#39;‰∫å&#39;</span><span class="p">,</span> <span class="s1">&#39;Â∑û&#39;</span><span class="p">,</span><span class="s1">&#39;Â≠¶Ê†°&#39;</span><span class="p">,</span><span class="s1">&#39;Á¨¨‰∏Ä&#39;</span><span class="p">,</span><span class="s1">&#39;ÈôÑÂ±û‰∏≠Â≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏≠Â≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;Â∞èÂ≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;Á¨¨‰∫å&#39;</span><span class="p">,</span><span class="s1">&#39;Â§ßÂ≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏≠Â≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏≠ÂøÉÂ∞èÂ≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;ÈôÑÂ±û&#39;</span><span class="p">,</span><span class="s1">&#39;ÊïôÂ∏à&#39;</span><span class="p">,</span><span class="s1">&#39;Á†îÁ©∂Èô¢&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏≠ÂøÉ&#39;</span><span class="p">,</span><span class="s1">&#39;È´òÁ∫ß‰∏≠Â≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;Âå∫ÊôØËãë&#39;</span><span class="p">,</span><span class="s1">&#39;ÂàÜÈô¢&#39;</span><span class="p">,</span><span class="s1">&#39;Â§ñÂõΩËØ≠&#39;</span><span class="p">,</span><span class="s1">&#39;Ëøõ‰øÆÂ≠¶Ê†°&#39;</span><span class="p">,</span><span class="s1">&#39;Á¨¨‰∏â&#39;</span><span class="p">,</span><span class="s1">&#39;Â∏àËåÉÂ§ßÂ≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;Â∏àÂ§ßÈôÑ‰∏≠&#39;</span><span class="p">,</span><span class="s1">&#39;ÁßëÊäÄ&#39;</span><span class="p">,</span><span class="s1">&#39;Á†îÁ©∂&#39;</span><span class="p">,</span><span class="s1">&#39;Á¨¨‰∏âÂçÅ‰πù&#39;</span><span class="p">,</span><span class="s1">&#39;‰∏≠ÊúóÊÇ¶&#39;</span><span class="p">,</span><span class="s1">&#39;ÈõÜÂõ¢&#39;</span><span class="p">,</span><span class="s1">&#39;Á†îÁ©∂ÊâÄ&#39;</span><span class="p">,</span><span class="s1">&#39;ÂÜúÊùë&#39;</span><span class="p">,</span><span class="s1">&#39;ÈôàÁªèÁ∫∂&#39;</span><span class="p">,</span><span class="s1">&#39;Èò≥ÂÖâ&#39;</span><span class="p">,</span><span class="s1">&#39;ÁßëÂ≠¶&#39;</span><span class="p">,</span><span class="s1">&#39;Èî¶Áª£&#39;</span><span class="p">,</span><span class="s1">&#39;ÂõΩÈôÖ&#39;</span><span class="p">,</span><span class="s1">&#39;Á¨¨‰∏ÉÂçÅ‰πù&#39;</span><span class="p">,</span><span class="s1">&#39;‰ø°ÊÅØÂ∑•Á®ã&#39;</span><span class="p">])</span>
   
    <span class="c1"># Use jieba for word segmentation</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
    
    <span class="c1"># Filter out stopwords and non-Chinese characters</span>
    <span class="n">filtered</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> 
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> 
           <span class="s1">&#39;</span><span class="se">\u4e00</span><span class="s1">&#39;</span> <span class="o">&lt;=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="s1">&#39;</span><span class="se">\u9fff</span><span class="s1">&#39;</span> <span class="ow">and</span> 
           <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered</span><span class="p">)</span>

<span class="c1"># 3. Generate corpus</span>
<span class="n">all_titles</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Âú∞Âå∫&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">())</span>
<span class="n">processed_text</span> <span class="o">=</span> <span class="n">process_text</span><span class="p">(</span><span class="n">all_titles</span><span class="p">)</span>

<span class="c1"># 4. Count word frequency</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">processed_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="c1"># 5. Generate word cloud</span>
<span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span>
    <span class="n">font_path</span><span class="o">=</span><span class="s2">&quot;/System/Library/Fonts/Supplemental/Songti.ttc&quot;</span><span class="p">,</span>  
    <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>  
    <span class="n">max_words</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>            
    <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>   
    <span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span>        
<span class="p">)</span>

<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">wc</span><span class="o">.</span><span class="n">generate_from_frequencies</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span>

<span class="c1"># visualisation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">wordcloud</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s1">&#39;english_learning_wordcloud.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0fc61567bfb7759c9351c17ae2e439ea714e63865d95f9868bd9d964e9f2cebf.png" src="_images/0fc61567bfb7759c9351c17ae2e439ea714e63865d95f9868bd9d964e9f2cebf.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;wordcloud.wordcloud.WordCloud at 0x16d50fef0&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="conclusion">
<h2>8. Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>This project focuses on analysing the thematic trends of manuscripts published in the journal <em>English Language Learning</em> by applying natural language processing (NLP) techniques using Python. The manuscript titles, exported in Excel format from the editorial system, were first imported and processed using the <code class="docutils literal notranslate"><span class="pre">pandas</span></code> library. Chinese word segmentation was performed with the <code class="docutils literal notranslate"><span class="pre">jieba</span></code> package, and a custom stopword list was applied to remove common but semantically insignificant words, as well as non-Chinese characters, thereby enhancing the focus and clarity of the extracted keywords.</p>
<p>Following text processing, word frequency statistics were calculated using the <code class="docutils literal notranslate"><span class="pre">Counter</span></code> module. The <code class="docutils literal notranslate"><span class="pre">wordcloud</span></code> and <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> libraries were then used to visualize the results in the form of a word cloud. The visualization clearly highlights frequently occurring terms such as ‚ÄúÈòÖËØª‚Äù (reading), ‚ÄúÊÄùÁª¥‚Äù (thinking), ‚ÄúÂÜô‰Ωú‚Äù (writing), ‚ÄúËØæÂ†Ç‚Äù (classroom), ‚ÄúÊ¥ªÂä®‚Äù (activity), and ‚ÄúËØ≠ÁØá‚Äù (text/discourse), indicating that current research in the journal places a strong emphasis on reading instruction, cognitive development, writing pedagogy, and classroom-based practices. These findings not only reflect ongoing trends in language education research but also provide data-driven insights into the journal‚Äôs topical orientation.</p>
<p>This project demonstrates the effective application of natural language processing in the analysis of educational text data. It offers an end-to-end pipeline from data import and preprocessing to statistical analysis and visualization. The method presented is scalable and adaptable, with the potential to be applied in other contexts such as tracking topic evolution, identifying research hotspots, and optimizing editorial strategies in academic publishing. As such, it contributes to the broader goal of promoting digital and intelligent approaches in education research.</p>
</section>
<section id="what-did-i-learn">
<h2>What did I learn?<a class="headerlink" href="#what-did-i-learn" title="Link to this heading">#</a></h2>
<p>Building this pipeline was actually straightforward, but deciding what to keep or discard (in text cleaning) took the most thought.
I now appreciate how useful a domain-specific stopword list is. Generic ones don‚Äôt work well in educational contexts.
Visualization helps, but interpretation is key. A word cloud is just a starting point ‚Äî I had to think about why certain words stood out and what they represented.
More personally:</p>
<p>I liked doing this kind of mini-project. It felt like a mix of editing, language analysis, and data work ‚Äî all things I enjoy.
It gave me ideas for bigger things I might try next (e.g., topic modeling, cross-year comparisons, author-based trends).</p>
</section>
<section id="what-could-be-better">
<h2>What could be better?<a class="headerlink" href="#what-could-be-better" title="Link to this heading">#</a></h2>
<p>If I had more time, I‚Äôd love to:</p>
<p>Use TF-IDF instead of raw word counts (to highlight more unique terms)
Try topic modeling (like LDA) to see if articles cluster into different themes
Track keyword changes over time (like a mini ‚Äúresearch trend report‚Äù)
Also‚Ä¶ make the word cloud prettier. But that‚Äôs just me being picky.</p>
</section>
<section id="final-thought">
<h2>Final thought<a class="headerlink" href="#final-thought" title="Link to this heading">#</a></h2>
<p>This wasn‚Äôt a big or fancy project, but it was honest and useful. I got to work with real data from my field, sharpen my Python skills, and reflect on what‚Äôs happening in English education research ‚Äî all at once.</p>
<p>Sometimes that‚Äôs all you need: a small project, a real question, and a few good tools.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="notebooks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Content with notebooks</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-this-project-about">What is this project aboutÔºü</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-did-i-do-it">Why did i do itÔºü</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-tools-did-i-use">What tools did I useÔºü</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-import">1. Data import</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing">2. Data processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-generating">3. Corpus Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-frequency-counting">4. Word frequency counting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wordcloud-generating">5. Wordcloud Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisation">6. Visualisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">7. Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-small-side-quest-regional-word-cloud">A small side questÔºöregional word cloudÔºÅ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">8. Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-i-learn">What did I learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-could-be-better">What could be better?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-thought">Final thought</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>