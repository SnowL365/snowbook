
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>My first Project1 &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'wordcloud';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Content with notebooks" href="notebooks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Hi, this is Snowâ€™s Program Channel â€” Snowbook ğŸ“˜â„ï¸
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="markdown.html">Markdown Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">Content with notebooks</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Wordcloud Project</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fwordcloud.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/wordcloud.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>My first Project1</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-this-project-about">What is this project aboutï¼Ÿ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-did-i-do-it">Why did i do itï¼Ÿ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-tools-did-i-use">What tools did I useï¼Ÿ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-import">1. Data import</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing">2. Data processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-generating">3. Corpus Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-frequency-counting">4. Word frequency counting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wordcloud-generating">5. Wordcloud Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisation">6. Visualisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">7. Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-small-side-quest-regional-word-cloud">A small side questï¼šregional word cloudï¼</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">8. Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-i-learn">What did I learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-could-be-better">What could be better?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-thought">Final thought</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="my-first-project1">
<h1>My first Project1<a class="headerlink" href="#my-first-project1" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<section id="what-is-this-project-about">
<h2>What is this project aboutï¼Ÿ<a class="headerlink" href="#what-is-this-project-about" title="Link to this heading">#</a></h2>
<p>This little project started with a super practical need at work: I had access to a batch of article titles from the English Language Learning journal, and I wanted to know â€” what are people actually writing about? What topics are trending? What do researchers seem to care about the most?</p>
<p>I figured a word cloud could be a quick, intuitive way to get a sense of it. More importantly, I wanted to use this as a chance to play around with Python + NLP tools on real data from my field (language education). So, this became both a content analysis project and a personal practice assignment rolled into one.</p>
</section>
<section id="why-did-i-do-it">
<h2>Why did i do itï¼Ÿ<a class="headerlink" href="#why-did-i-do-it" title="Link to this heading">#</a></h2>
<p>To be honest, Iâ€™ve always felt that journal content can feel a bitâ€¦ abstract or scattered if you just skim through titles. But if we could pull all the titles together and extract keywords, patterns might emerge. This kind of small project can be useful for:</p>
<p>Guiding editorial direction (what themes are we already overloaded with?)
Helping contributors see whatâ€™s hot (or overdoneâ€¦)
Just satisfying my curiosity :ï¼‰
Also, as someone learning data tools, I wanted to test-drive some basic NLP workflows: text cleaning, segmentation, frequency analysis, visualization â€” all in Python.</p>
</section>
<section id="what-tools-did-i-use">
<h2>What tools did I useï¼Ÿ<a class="headerlink" href="#what-tools-did-i-use" title="Link to this heading">#</a></h2>
<p>Pretty standard setup:</p>
<p><code class="docutils literal notranslate"><span class="pre">pandas</span></code> â€“ for loading the Excel data (which came straight from the editorial system)
<code class="docutils literal notranslate"><span class="pre">jieba</span></code> â€“ for Chinese word segmentation
<code class="docutils literal notranslate"><span class="pre">counter</span></code> â€“ to count word frequency
<code class="docutils literal notranslate"><span class="pre">wordcloud</span></code> â€“ for visualizing the results
<code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> â€“ for showing the image
Also, I had to deal with font paths on my Mac (because Chinese in wordcloud needs a proper .ttc font).</p>
</section>
<section id="data-import">
<h2>1. Data import<a class="headerlink" href="#data-import" title="Link to this heading">#</a></h2>
<p>First things first â€” I started by importing the basic libraries I needed for the project. Nothing too fancy, just the usual stack for working with Excel files and doing some text processing in Python.</p>
<p>The data itself came from my actual work â€” we use an editorial system that stores manuscript info, and it luckily allows us to export everything directly as an Excel file. Super convenient! I didnâ€™t have to clean raw HTML or scrape anything â€” just hit â€œExportâ€ and I was ready to go.</p>
<p>So I wrote this to load things up:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">jieba</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;jieba&#39;
</pre></div>
</div>
</div>
</div>
<p>Then I loaded the file like this:
ã€A small thing I noticed: the actual header (column names) were on the second row in the Excel file, so I had to set header=1 to read it properly. Without that, df[â€˜æ ‡é¢˜â€™] wouldnâ€™t work later.ã€‘</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;/Users/snowliu/Downloads/20250307170539.xls&quot;</span>

<span class="c1"># Read Excel</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s2">&quot;ç¨¿ä»¶ä¿¡æ¯&quot;</span><span class="p">,</span><span class="n">header</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>           ç¨¿ä»¶ç¼–å·                                                 æ ‡é¢˜  å­—æ•° ç¬¬ä¸€ä½œè€…å§“å  \
0    2016040025                                    ä¾‹è°ˆå•å…ƒå¯¼è¯»è¯¾çš„è¯¾å ‚è®¾è®¡ä¸åæ€ NaN    è‘›å©·å©·   
1    2023080023                                 ç§‘æ™®æ•…äº‹èåˆé˜…è¯»æ•™å­¦è·¯å¾„çš„è®¾è®¡ä¸å®æ–½ NaN     å¾æ™¶   
2    2021070023                                     â€œéª¨æ¶æ–‡æœ¬â€ä¸­æ€ç»´è®­ç»ƒçš„é“ºå±• NaN    é¡¾å°äº®   
3    2016010009  æµ…æè¯‘æ—ç‰ˆã€Šè‹±è¯­ã€‹ticking timeæ¿å—çš„ æœ‰æ•ˆæ•™å­¦â€”â€”ä»¥è¯‘æ—ç‰ˆã€Šè‹±è¯­ã€‹3B Unit... NaN     æ²ˆèŠ¸   
4    2016040034                                 é«˜ä¸­è‹±è¯­é˜…è¯»æ•™å­¦ä¸­å¼€å±•è¯»åç»­å†™çš„å°è¯• NaN     å¼ å¼º   
..          ...                                                ...  ..    ...   
160  2020040045                  åœ¨è¿‡ç¨‹æ€§æ•™å­¦ä¸­è¿ç”¨StorytellingåŸ¹å…»å­¦ç”Ÿçš„è¾“å‡ºæ€§è¯­è¨€æŠ€èƒ½ NaN    ç‹å›å…ƒ   
161  2023020032       ä»è¯„å§”ç‚¹è¯„åè§‚é˜…è¯»æ•™å­¦çš„è®¤çŸ¥æƒ…å†µ â€”â€”ä»¥11-13å±Šå…¨å›½åˆä¸­è‹±è¯­è¯¾å ‚æ•™å­¦è§‚æ‘©åŸ¹è®­è¯¾ä¸ºä¸ªæ¡ˆ NaN    é™ˆèƒ½æ˜Š   
162  2023030090  åŸºäºè‹±è¯­å­¦ä¹ æ´»åŠ¨è§‚çš„å¯¹è¯æ•™å­¦ç­–ç•¥ â€”â€”ä»¥PEPäº”å¹´çº§ä¸Šå†ŒUnit 5 There is a ... NaN    è®¸ç»´ç»´   
163  2024010133           ä¸»é¢˜è¯­å¢ƒå¼•é¢†ä¸‹çš„é«˜ä¸­è‹±è¯­è¯­æ³•æ•™å­¦ï¼šå¤–ç ”ç‰ˆã€Šè‹±è¯­ã€‹ï¼ˆæ–°æ ‡å‡†ï¼‰ç¬¬äºŒå†Œç¬¬å…­å•å…ƒæ¡ˆä¾‹åˆ†æ NaN     ä¸›è•¾   
164  2023110060                                   åœ¨è‹±è¯­è¯¾å ‚ä¸­è§†é¢‘æ•™å­¦çš„æ¢è®¨ä¸å®è·µ NaN    è®¸æ—¶å‡   

         ç¬¬ä¸€ä½œè€…å•ä½             ç¬¬ä¸€ä½œè€…E-mail ç¬¬äºŒä½œè€…å§“å     ç¬¬äºŒä½œè€…å•ä½            ç¬¬äºŒä½œè€…Email  \
0    æ±Ÿè‹çœå—é€šç”°å®¶ç‚³ä¸­å­¦       810136381@qq.com    NaN        NaN                  NaN   
1     å¤§è¿å¸‚ç¬¬ä¸ƒåä¹ä¸­å­¦        14910333@qq.com    å¤æºæ¢“  å¤§è¿å¸‚ç¬¬äºŒåå…«ä¸­å­¦    1210572318@qq.com   
2           NaN  guxiaoliang_l@163.com    NaN        NaN                  NaN   
3     æ˜†å±±å¸‚ç¬¬ä¸€ä¸­å¿ƒå°å­¦       252139079@qq.com    NaN        NaN                  NaN   
4       æµ™æ±Ÿçœå¹³æ¹–ä¸­å­¦   dashenlin123@163.com    NaN        NaN                  NaN   
..          ...                    ...    ...        ...                  ...   
160      æ­å·äº‘è°·å­¦æ ¡  angela.wang@yungu.org    è°¢æ…§è     æ­å·äº‘è°·å­¦æ ¡  grace.xie@yungu.org   
161         NaN       eddiecnh@163.com    åº”å»ºèŠ¬     æµ™æ±Ÿå¸ˆèŒƒå¤§å­¦       zsdyjf@zjnu.cn   
162         NaN       412191495@qq.com    NaN        NaN                  NaN   
163   å±±ä¸œçœçƒŸå°ç¬¬ä¸€ä¸­å­¦       842762843@qq.com    NaN        NaN                  NaN   
164         NaN       443613995@qq.com    ç½—å½©ç”œ   ä½›å±±å¸‚å¤–å›½è¯­å­¦æ ¡      lct2626@126.com   

    ç¬¬ä¸‰ä½œè€…å§“å  ...                 æŠ•ç¨¿æ—¶é—´  è”ç³»äºº                               é€šä¿¡åœ°å€  \
0      NaN  ...   2016/4/19 15:48:12  è‘›å©·å©·                         æ±Ÿè‹çœå—é€šç”°å®¶ç‚³ä¸­å­¦   
1      NaN  ...    2023/8/7 15:57:04   å¾æ™¶        å¤§è¿å¸‚æ²™æ²³å£åŒºè²èŠ±å±±è·¯104å·1å•å…ƒ4æ¥¼1å·ææ°¸åå¥³å£«   
2      NaN  ...    2021/7/9 15:00:46  é¡¾å°äº®                                NaN   
3      NaN  ...   2016/1/12 19:08:49   æ²ˆèŠ¸            æ±Ÿè‹çœæ˜†å±±å¸‚é›†è¡—178å· ç¬¬ä¸€ä¸­å¿ƒå°å­¦ï¼ˆåˆ†éƒ¨ï¼‰   
4      NaN  ...   2016/4/25 14:38:51   å¼ å¼º                     æµ™æ±Ÿçœå¹³æ¹–å¸‚ä¸œæ¹–å¤§é“831å·   
..     ...  ...                  ...  ...                                ...   
160    NaN  ...   2020/4/16 22:21:19  ç‹å›å…ƒ                   æ­å·å¸‚è¥¿æ¹–åŒºæ˜¥ç”³è¡—17å·äº‘è°·å­¦æ ¡   
161    NaN  ...    2023/2/9 18:17:14  é™ˆèƒ½æ˜Š            æµ™æ±Ÿçœé‡‘åå¸‚å©ºåŸåŒºè¿å®¾å¤§é“688å·æµ™æ±Ÿå¸ˆèŒƒå¤§å­¦   
162    NaN  ...   2023/3/23 17:53:27  è®¸ç»´ç»´                                NaN   
163    NaN  ...   2024/1/29 18:07:36   ä¸›è•¾  19953516726 å±±ä¸œçœçƒŸå°å¸‚è±å±±åŒºå‰ä¸ƒå¤¼å¤©æˆè¥¿å··50-11   
164    NaN  ...  2023/11/18 15:11:11  è®¸æ—¶å‡                                NaN   

         é‚®æ”¿ç¼–ç              åº§æœº          ç§»åŠ¨ç”µè¯               è”ç³»äººEmail  \
0    226001.0  0513-81100295  1.386294e+10       810136381@qq.com   
1    116021.0       84312203  1.305277e+10        14910333@qq.com   
2         NaN            NaN  1.824890e+10  guxiaoliang_l@163.com   
3    215300.0            NaN  1.525029e+10       252139079@qq.com   
4    314200.0            NaN  1.375735e+10   dashenlin123@163.com   
..        ...            ...           ...                    ...   
160       NaN            NaN  1.760581e+10  angela.wang@yungu.org   
161  321004.0            NaN  1.786063e+10       eddiecnh@163.com   
162       NaN            NaN  1.588817e+10       412191495@qq.com   
163  264001.0            NaN  1.856130e+10       842762843@qq.com   
164       NaN            NaN  1.813832e+10       443613995@qq.com   

              çŠ¶æ€ ç¬¬ä¸€ä½œè€…ORCID        åœ°åŒº  
0    ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN  å®‰å¾½çœå®¿å·å¸‚    
1    ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN     å·´ä¸­å¸‚    
2    ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN      åŒ—äº¬    
3    ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN      åŒ—äº¬    
4    ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN      åŒ—äº¬    
..           ...       ...       ...  
160  ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN       NaN  
161  ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN       NaN  
162  ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN       NaN  
163  ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN       NaN  
164  ç¼–è¾‘éƒ¨å¤„ç†å®Œæ¯•[å½•ç”¨]       NaN       NaN  

[165 rows x 22 columns]
</pre></div>
</div>
</div>
</div>
<p>As you can see, I just threw all the titles into a word cloud without any cleaning. Big mistake. The top words were super generic: things like â€œçš„â€ (â€˜s), â€œä¸â€ (and), â€œä¸ºä¾‹â€ (a case study ofâ€¦)â€¦ basically, words that show up in almost every academic title. I need to do somethingï¼</p>
</section>
<section id="data-processing">
<h2>2. Data processing<a class="headerlink" href="#data-processing" title="Link to this heading">#</a></h2>
<p>So I made a custom stopword list, based on what I see over and over in educational writing. This step turned out to be the most valuable â€” it made the final output much clearer.</p>
<p>Also:</p>
<p>I kept only Chinese words (filtering out symbols and punctuation)
I excluded words shorter than 2 characters
I joined all titles into one string before segmentation
This whole process reminded me that clean data beats fancy tools. Even the best word cloud wonâ€™t help if your data is full of noise.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2. Processing Chinese word segmentation</span>
<span class="k">def</span> <span class="nf">process_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># Custom stopword list: Since many meaningless words exist in these titles, they need to be removed in order to retain only the key terms.</span>
    <span class="n">stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39;çš„&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸&#39;</span><span class="p">,</span> <span class="s1">&#39;åŠ&#39;</span><span class="p">,</span> <span class="s1">&#39;åœ¨&#39;</span><span class="p">,</span> <span class="s1">&#39;åŸºäº&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸‹&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸­&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¾‹&#39;</span><span class="p">,</span> <span class="s1">&#39;ä»¥&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸ºä¾‹&#39;</span><span class="p">,</span> <span class="s1">&#39;â€”â€”&#39;</span><span class="p">,</span> <span class="s1">&#39;å®è·µ&#39;</span><span class="p">,</span> <span class="s1">&#39;ç ”ç©¶&#39;</span><span class="p">,</span> <span class="s1">&#39;æ•™å­¦&#39;</span><span class="p">,</span> <span class="s1">&#39;è®¾è®¡&#39;</span><span class="p">,</span> <span class="s1">&#39;ç­–ç•¥&#39;</span><span class="p">,</span> <span class="s1">&#39;æ¢ç©¶&#39;</span><span class="p">,</span><span class="s1">&#39;åˆ›è®¾&#39;</span><span class="p">,</span><span class="s1">&#39;è‹±è¯­&#39;</span><span class="p">,</span><span class="s1">&#39;é«˜ä¸­è‹±è¯­&#39;</span><span class="p">,</span><span class="s1">&#39;æµ…æ&#39;</span><span class="p">,</span><span class="s1">&#39;è¯¾ä¸ºä¾‹&#39;</span><span class="p">,</span><span class="s1">&#39;ä¿ƒè¿›&#39;</span><span class="p">,</span><span class="s1">&#39;ç›¸ç»“åˆ&#39;</span><span class="p">,</span><span class="s1">&#39;å­¦ç”Ÿ&#39;</span><span class="p">,</span><span class="s1">&#39;å­¦ä¹ &#39;</span><span class="p">,</span><span class="s1">&#39;åŸ¹å…»&#39;</span><span class="p">,</span><span class="s1">&#39;è¿ç”¨&#39;</span><span class="p">,</span><span class="s1">&#39;æ¢ç´¢&#39;</span><span class="p">,</span><span class="s1">&#39;åŠå…¶&#39;</span><span class="p">,</span><span class="s1">&#39;å°è¯•&#39;</span><span class="p">,</span><span class="s1">&#39;å¦‚ä½•&#39;</span><span class="p">,</span><span class="s1">&#39;æå‡&#39;</span><span class="p">,</span><span class="s1">&#39;æ•´åˆ&#39;</span><span class="p">,</span><span class="s1">&#39;æé«˜&#39;</span><span class="p">,</span><span class="s1">&#39;åˆä¸­&#39;</span><span class="p">,</span><span class="s1">&#39;åˆä¸­ç”Ÿ&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸€èŠ‚&#39;</span><span class="p">,</span><span class="s1">&#39;åˆ†æ&#39;</span><span class="p">,</span><span class="s1">&#39;æœ‰æ•ˆ&#39;</span><span class="p">,</span><span class="s1">&#39;å¤šè½®&#39;</span><span class="p">,</span><span class="s1">&#39;æ•™è‚²&#39;</span><span class="p">,</span><span class="s1">&#39;ä¾æ‰˜&#39;</span><span class="p">,</span><span class="s1">&#39;é€šè¿‡&#39;</span><span class="p">,</span><span class="s1">&#39;å°å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;åˆä¸­è‹±è¯­&#39;</span><span class="p">,</span><span class="s1">&#39;é«˜ä¸­ç”Ÿ&#39;</span><span class="p">,</span><span class="s1">&#39;å¼€å±•&#39;</span><span class="p">,</span><span class="s1">&#39;æŒ‡å‘&#39;</span><span class="p">,</span><span class="s1">&#39;é«˜ä¸­&#39;</span><span class="p">,</span><span class="s1">&#39;ç»“åˆ&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸­å­¦è‹±è¯­&#39;</span><span class="p">,</span><span class="s1">&#39;é—®é¢˜&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸ºä¾‹&#39;</span><span class="p">,</span><span class="s1">&#39;ä¾‹è°ˆ&#39;</span><span class="p">,</span><span class="s1">&#39;è¯‘æ—&#39;</span><span class="p">,</span><span class="s1">&#39;èåˆ&#39;</span><span class="p">,</span><span class="s1">&#39;é˜…è¯»æ•™å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸­å°&#39;</span><span class="p">])</span>
    
    <span class="c1"># Use Jieba for word segmentation</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
    
    <span class="c1"># Filter out stopwords and non-Chinese characters</span>
    <span class="n">filtered</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> 
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> 
           <span class="s1">&#39;</span><span class="se">\u4e00</span><span class="s1">&#39;</span> <span class="o">&lt;=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="s1">&#39;</span><span class="se">\u9fff</span><span class="s1">&#39;</span> <span class="ow">and</span> 
           <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="corpus-generating">
<h2>3. Corpus Generating<a class="headerlink" href="#corpus-generating" title="Link to this heading">#</a></h2>
<p>In this step, I can generate a corpus from the title keywords after word segmentation and filtering.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate corpus</span>
<span class="n">all_titles</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;æ ‡é¢˜&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">())</span>
<span class="n">processed_text</span> <span class="o">=</span> <span class="n">process_text</span><span class="p">(</span><span class="n">all_titles</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then I print the filtered keywords.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">processed_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>å•å…ƒ å¯¼è¯» è¯¾å ‚ åæ€ ç§‘æ™® æ•…äº‹ è·¯å¾„ å®æ–½ éª¨æ¶ æ–‡æœ¬ æ€ç»´ è®­ç»ƒ é“ºå±• æ¿å— åç»­ èº«ä¸´å…¶å¢ƒ ä¹åœ¨å…¶ä¸­ è¯­ç¯‡ æ„è¯† åˆ›ç¼– å¯¹è¯ èƒ½åŠ› è¡”æ¥ è‡ªç„¶ æ‹¼è¯» å›½é™…éŸ³æ ‡ è¯­éŸ³ æ•™å­¦ç­–ç•¥ åˆæ¢ è§£ç  ç»˜æœ¬ æ‰¹æ³¨ é˜…è¯» ç´ å…» å•å…ƒ æ´»åŠ¨ æ ‡é¢˜ ä¸€ä½“åŒ– æˆå‰§ ä»²å¤å¤œ ä¹‹æ¢¦ é€†å‘ å•å…ƒ å†™ä½œ æ•™ç‰ˆ å…«å¹´çº§ ä¸‹å†Œ é€†å‘ ç†å¿µ æŒ‡å¯¼ å¯¹è¯ è‹±å›½ æ°‘æ— èº«ä»½ ç¤¾ä¼š æ–‡åŒ– è§†é˜™ ç»´å¤šåˆ©äºš æ·‘å¥³ å…¸èŒƒ æ¨¡å‹ æ•™æ é¡¹ç›® äººæ•™ç‰ˆ é€‰ä¿® æ¿å— æ”¹å˜ æ•™å¸ˆ è¯è¯­ è¯¾å ‚ å‚ä¸åº¦ è¡ŒåŠ¨ ä¿®æ”¹ ä¸‰æ–° èƒŒæ™¯ ä¸­å°å­¦ æ•™å¸ˆ æ–‡å­¦ ç´ å…» è·¯å¾„ è‹±è¯­æ•™æ å¯¹è¯ éƒ¨åˆ† è¯å— ç»“æ„åŒ– çŸ¥è¯† ä½œä¸º ä¸»çº¿ å•å…ƒ æ•´ä½“ è·¯å¾„ ä»¥å¤– ç ”ç‰ˆ åˆäºŒ è®¾è®¡è¯´æ˜ æ„å»º ä»»åŠ¡ ç›®æ ‡ åˆç† å®šä½ ä¾‹æ æ–‡å­¦ è¯¾å¤–é˜…è¯» æ–‡æœ¬ è§£è¯» ä»¥å†™ ä¿ƒè¯» ç†å¿µ æŠ¥åˆŠ æ‰¹æ³¨ é˜…è¯» èŒƒæ–‡ å†™ä½œ æ„ä¹‰ åº”ç”¨ è¯­æ–™åº“ æŠ€æœ¯ è¯»å†™èƒ½åŠ› å¤šç»´ é˜…è¯» æ•…äº‹ å¤±è¸ª ç€çœ¼ æ•´ä½“ ä¼˜åŒ– å¬å‰ æ´»åŠ¨ åŒ—å¸ˆå¤§ å¬è¯´ ç›®æ ‡ è®¾å®š å•å…ƒ æ•´ä½“ ä½œä¸š è¿›é˜¶ é˜…è¯» å†™ä½œ ååŒ å‘å±• ç¾¤æ–‡ è¯»å†™ è¯¾å ‚ ç»˜æœ¬ è¯»å†™ åŒå‘ èé€š æ•™å­¦ç­–ç•¥ å°åˆ è¡”æ¥ ç°çŠ¶ æ€è€ƒ ä»¥åŒ å¼‚æ„ é˜…è¯» æ‹“å±• äº§å‡º å¯¼å‘ è§†åŸŸ è¯»å†™ å¯¹ç­– åŸºæœ¬ ç§ä¸‹ å¯¹è¯ åº”å¯¹ æ–¹å¼ å¯¹è¯ å£è¯‘ è¯‘å‘˜ è§’è‰² è¡¨ç° çœ¼ç¥ äº’åŠ¨ è½¬æ¢ ä¸¤é¡¹ æŒ‡æ ‡ æ¡ˆä¾‹ ç²¾è®¾ æ„å»º é«˜æ•ˆ è¯¾å ‚ ç‰›æ´¥ ä¸Šæµ· æ•…äº‹ æ¿å— åŒé‡ è§’è‰² é˜…è¯» æ¨¡å¼ æ•…äº‹ åˆ›æ–° åº”ç”¨ å…«å¹´çº§ å…¸èŒƒ æ•…äº‹ é˜…è¯»è¯¾ æ ¹æ® æ–°é—» è¯­ç¯‡ ç‰¹ç‚¹ æŒ‡å¯¼ æ–°é—» å¬è¯´ å¾ªç¯å¼ è¯¾å ‚ æ´»åŠ¨ ç¤¾ä¼šä¸»ä¹‰ æ ¸å¿ƒ ä»·å€¼è§‚ å†™ä½œ å‘½é¢˜ æ¸—é€ è¿‡ç¨‹ å–å‘ å¬åŠ› å…¬å¼€è¯¾ ç‰‡æ®µ è¯„æ æ€è€ƒ æ·±å±‚ æ–‡æœ¬ è§£è¯» ä¸­å­¦ç”Ÿ æ€ç»´èƒ½åŠ› ç ”ç‰ˆ æ ‡å‡† äº”å¹´çº§ ä¸Šå†Œ ä¾‹è®® è¯¾å ‚æ•™å­¦ æ€ç»´ çµæ´»æ€§ å†™ä½œ æ•™å­¦ç­–ç•¥ æ ¡é™… åä½œ æ•™ç ” æ¨¡å¼ æ¬§æ´² æˆ‘å›½ å¤–è¯­ æ”¹é© æ­£å¼ èšç„¦ ä¸»é¢˜ è¯­å¢ƒ é˜…è¯» æ•™å­¦æ¨¡å¼ å·§å€Ÿ è¯­æ³• è¯¾å ‚ åŠ©æ¨ æ€ç»´ å‘å±• é˜…è¯» è¯¾å ‚ ç§¯æ åé¦ˆ è®¤çŸ¥ æ”¯æ¶ åŠŸèƒ½ ç‰¹å¾ è§†å¬ è¯¾ä¸­ æ‰¹åˆ¤æ€§ æ€ç»´ é¢˜ä¸º å…«å¹´çº§ è§†å¬ å›´ç»• è¯é¢˜ æƒ…å¢ƒ æ¿€å‘ æ€ç»´ è¿‡ç¨‹ å†™ä½œ é«˜é˜¶ æ€ç»´ é˜…è¯»è¯¾ è¯»å æ´»åŠ¨ ä¸»é¢˜ æ„ä¹‰ å¤è¿° å†™ä½œæ°´å¹³ å°å­¦ç”Ÿ åˆ›æ–° ç²¾ç¥ ç»˜æœ¬ é˜…è¯» æ€è€ƒ è¯­ç¯‡ ç»„ç»‡ æ¨¡å¼ è¯´æ˜æ–‡ æ–‡æœ¬ è§£æ„ å¤šå…ƒ æ”¯æ¶ è¯—æ­Œ å®æ•ˆ ä»ç™½ ç‰¡ä¸¹äº­ è‹±è¯‘æœ¬ ä¸­å›½ å¤å…¸ æˆå‰§ è‹±è¯‘ è¡¨æ¼”æ€§ æ ¸å¿ƒ ç´ å…» è¯´æ˜æ–‡ èƒŒè¯µ ä¸€ä½“åŒ– å¸ˆç”Ÿ å…±è¯» æ•´æœ¬ä¹¦ é˜…è¯» æŒ‡å¯¼ èƒ½åŠ› å¬è¯´ è¯„ä»· å®æ–½ å•å…ƒ ä½œä¸š å‡è½» ä½œä¸šè´Ÿæ‹… è¡ŒåŠ¨ äººæ•™ç‰ˆ ä¸€å¹´çº§ èµ·ç‚¹ äº”ä¸Š å•å…ƒ ä½œä¸š å•å…ƒ æ•´ä½“ è§†è§’ å†™ä½œ å¯¹è¯ é¢„æµ‹ æŠ€å·§ æ ¸å¿ƒ ç´ å…» å¯¼å‘ æ–‡å­¦ è¯­ç¯‡ ç»†èŠ‚ æå†™ æ•™å­¦ç­–ç•¥ æ·±åº¦ åç»­ è¯¾å ‚æ•™å­¦ è¯„ä»· æ´»åŠ¨ å®æ–½ ç»˜æœ¬ æ•™æ æ–‡åŒ– æ„è¯† è¿æ¥ è§†è§’ è¯»å†™ å®æ–½ è·¯å¾„ è´å¤šèŠ¬ é»‘äºº çœ‹çº³ä¸ æˆˆè¿ªé»˜ æ™šæœŸ é£æ ¼ å•å…ƒ ä¸»é¢˜ æ„ä¹‰ ç»˜æœ¬ åˆæ¢ ä¸€å›¾ å¤šç”¨ è‹±è¯­æ•™æ å›¾ç‰‡ èµ„æº åˆ©ç”¨ å®æ•ˆ ä¸»é¢˜ æ„ä¹‰ ç»˜æœ¬ å¤šç»´ é˜…è¯» ç¬¬ä¸ƒçº§ ä¸€è¯¾ çœŸç† ç¨³å®šæ€§ çº¦ç¿°é€Š èè¯„ ç†æ€§ å¬å†™ é‡æ„ å¬è¯´ è¯¾ä¸­ æ„å»º ä¸€ä½“ è¯—æ­Œ æ¨¡å‹ æ–‡ä¸­ æ€å›¾ å¤–ç ” ç‰ˆå›¾ æ–‡å¼ æ•™æ ä¸»é¢˜ è¯­å¢ƒ è‹±è¯­è¯æ±‡ å¿ƒæ™º å›¾æ³• ä»¿å†™ ç»ƒä¹  åº”ç”¨ æ–°è¯¾æ ‡ æ·±åœ³ ç‰›æ´¥ ä¸‰å¹´çº§ å›¾ç‰‡ ä¿¡æ¯ å†æ„ æ–‡æœ¬ æ•™å­¦ç­–ç•¥ è‹±æ–‡ ç»˜æœ¬ é˜…è¯» è¯¾å ‚ æé—® è¿ç¯ æ”¹è¿› äº¤äº’ ååŒ å†™ä½œ æ­¥æ³• è‹±è¯­æ•™å­¦ åº”ç”¨ å•å…ƒ æ•´ä½“ æ•™æ æ’å›¾ äº”ç§ ä½¿ç”¨ æ–¹æ³• å…³äº é˜…è¯»è¯¾ å¼€æ”¾æ€§ å‚ä¸åº¦ è¡ŒåŠ¨ é‡æ–° ä¸€é ä¸­è¦ å¼ºåŒ– é˜…è¯» æ¸—é€ æ„è¯† ä¼šè¯ è¯­è¨€ æ‰¿è½½ æµ…è°ˆ è‹±è¯­è¯¾å ‚ ç«¥è¯æ•…äº‹ è¿›è¡Œ æ€ç»´ è®­ç»ƒ ä¸€å ‚ è¯¾é¢˜ å®éªŒè¯¾ æ•™ç ” æ‹“å±• æ¸ é“ å…­å¹´çº§ å†™ä½œèƒ½åŠ› æ€ç»´ å¯¼å›¾ è‹±æ–‡ å°è¯´ æ€ç»´ å“è´¨ æ¢ä¾‹ ç†è®º é«˜å¹´çº§ æé—® è¯¾å‹ å¯è§†åŒ– è¯Šæ–­ æµ‹è¯„ åŸºç¡€ æ•™å¸ˆ è¯¾å ‚ è¯„ä»· ç´ å…» å‘å±• ä¸ªæ¡ˆç ”ç©¶ è¯Šæ–­ ä¿ƒè¯„ ä»¥è¯„ ä¿ƒæ•™ è‹±è¯­è¯¾å ‚ å»ºç«‹ è¯„ä»· æ¨¡å¼ æˆå‰§ æ–‡å­¦ é˜…è¯» è¯¾å ‚ è¯­ç¯‡ è¯­å¢ƒ è‹±è¯­è¯­æ³• å¤ä¹  ä¸‰å·§ å®æ–½ å¾®è¯­ é˜…è¯» è¯­è¨€ çŸ¥è¯† å•å…ƒ ä¸»é¢˜ æ„ä¹‰ äº’åŠ¨ ååŒæ•ˆåº” åç»­ å­¦ç§‘ æ ¸å¿ƒ ç´ å…» æ´»åŠ¨ æ¢æ å¬è®° å¤è¿° å¬è¯´ èƒ½åŠ› æ€è€ƒ ä¿¡æ¯æŠ€æœ¯ æ”¯æŒ ä¹ æœ¬ åˆæ¢ åŸºæœ¬ é«˜ä¸­å­¦ç”Ÿ å­¦ç§‘ æ€ç»´ å“è´¨ ç»†è¯» æ³›è¯» å¤æ‚ æ–‡æœ¬ é˜…è¯» æ¨è¿› åç»­ å¬åŠ› æµ‹è¯„ åæ‹¨ å¬åŠ› è·¯å¾„ ç»˜æœ¬ é˜…è¯» æ‹¼è¯» è¯¾ä¸­ äº”å¹´çº§ ä¸Šå†Œ è¯­æ–™åº“ è¯è¯­ æ­é… åº”ç”¨ å¯ç¤º è”æ¥ é¡¹ç›® æ´»åŠ¨ ç”Ÿæ´»å®è·µ è¯¾å‹ åº”ç”¨æ–‡ é˜…è¯» è¯¾å ‚ åæ€ åˆ©ç”¨ æ•™æ æ’å›¾ ä¼˜åŒ– è¯­ç¯‡ ä¾¦æ¢ ç ´æ¡ˆ æƒ…å¢ƒ åˆ›æ–° æ–‡å­¦ èµè¯» æ€è·¯ ç§‘æ™® è¯´æ˜æ–‡ æ€ç»´ è¯»å†™ ç»¼åˆè¯¾ æ¶æ„ æ‹¼å›¾ é˜…è¯» ç§‘æ™® ç»˜æœ¬ åº”ç”¨ ç»˜æœ¬ ç»¼åˆ è§†è§’ è·¯å¾„ æ¢æ ç‹¬ç™½ æ–‡æœ¬ å¬è¯´ åæ€ è¯­ç¯‡ ä¸»é¢˜ æ„ä¹‰ è¯»å è¯æ±‡ å·©å›º æ´»åŠ¨ ç°æœ‰ è®¤çŸ¥ åŸºç¡€ å‘å±• è¯­è¨€ èƒ½åŠ› æ€ç»´ å“è´¨ æ–‡å­¦ è¯­ç¯‡ åç»­ æ´»åŠ¨ å¬åŠ› å¤šé¡¹ åŒ¹é… ä¸­å°å­¦ç”Ÿ æ€è¾¨ èƒ½åŠ› ä»·å€¼ æ¢æ èšç„¦ è®­ç»ƒ æ‹“å±• è‡ªå­¦ æ´»åŠ¨ æŒ‡å¯¼ é¡¹ç›® ç£¨è¯¾ ç»å† å°è¯´ æ–‡æœ¬ åç»­ å†™å¾® å‰§æœ¬ å¤šç»´ é˜…è¯» è¯»å†™ è¯­è¨€ æ€ç»´ åŒæ­¥ è½¬åŒ– æ•™å­¦ç­–ç•¥ è‹±è¯­è¯æ±‡ å­¦ä¹ ç­–ç•¥ è·¯å¾„ å½¢æˆ è¯„ä»· ä»»åŠ¡ è§†åŸŸ è¯»å†™èƒ½åŠ› å¤šç»´ é˜…è¯» è™šæ„ æ–‡æœ¬ å¸ˆç”Ÿ åˆä½œ è¯„ä»· åç»­ é¢„ä¹  ä¸‰å¹´çº§ å­¦å›°ç”Ÿ è½¬åŒ– è¡ŒåŠ¨ æ··åˆå¼ è‹±è¯­è¯­æ³• ä»¥è¯» ä¿ƒå†™ ä»¥å†™ ä¿ƒè¯» é©±åŠ¨ åŸç‰ˆä¹¦ è¯»å†™ æ–°è¯¾æ ‡ ç†å¿µ ä¸‰å¹´çº§ å¯¹è¯ æ•™å­¦æ¨¡å¼ å†æ„ ä»¥äº¬ç‰ˆ å…¸èŒƒ å°è¯´ è½½ä½“ ä»¥è¯» ä¿ƒå†™ åç»­ äººæ•™ç‰ˆ è‹±è¯­æ•™æ è¯»å ä»¿å†™ è¡”æ¥ é‡è¦ å…ƒç´  è¯Šæ–­ æµ‹è¯„ åç»­ æ”¯æ¶ æ­å»º è¯¾ä¾‹ å‚ä¸ èƒŒè¯µ æ¨¡å¼ å™äº‹ èƒŒè¯µ ä¸“é¢˜ è¯­ç¯‡ èƒŒè¯µ æ´»åŠ¨ è¯­è¨€ è¾“å‡º è´¨é‡ æ–‡å­¦ä½œå“ ä¸‰ç»´ è¿›é˜¶ ç»­å†™ æ ·å¼ å…¸èŒƒ ä¸»é¢˜ çŸ¥è¯† ç»“æ„åŒ– è‡ªä¸» æ ¸å¿ƒ ç´ å…» èƒŒæ™¯ æ€ç»´ å“è´¨ å‘å±• ç»˜æœ¬ è‹±è¯­æ•™å­¦ ç›®æ ‡ å¯¹ç­– å†™ä½œ è‡ªæˆ‘ è¯„ä»· è‹±è¯­æ•™å­¦ ä¿ƒæ€ è·¯å¾„ æ¨¡æ€ è¯­ç¯‡ ä»»åŠ¡ è‹±è¯­è¯¾å ‚ è¾©è®º è¯­è¨€ èƒ½åŠ› æ€ç»´ å“è´¨ ååŒ å‘å±• åˆæ¢ äººæ•™ç‰ˆ å…«å¹´çº§ ä¸‹å†Œ é˜…è¯»è¯¾ å°è¯´ æ„è¯†æµ è¯­è¨€ ç¿»è¯‘ å°¤åˆ©è¥¿æ–¯ åˆ˜è¯‘ ç®¡çª¥ çº¢æ¥¼æ¢¦ æ¨¡ç³Š é™åˆ¶ è‹±è¯‘ è¿‡ç¨‹ å†™ä½œ å‘å±• åˆ›é€ æ€§ æ€ç»´èƒ½åŠ› åŒä¼´ äº’è¯„ äº’è¯„ é‡è¡¨ å†™ä½œ ä¸»è¦ è§£å†³ ä¸»é¢˜ è¯­å¢ƒ è‹±è¯­è¯æ±‡ é™„å¸¦ æ•™å­¦ç­–ç•¥ æ´»åŠ¨ ç»¼åˆ æŠ€èƒ½ æ¿å— æ•™å­¦æ´»åŠ¨ å…³è”æ€§ æ€ç»´ å¯è§†åŒ– å·¥å…· æ•´æœ¬ä¹¦ è¯»å æ´»åŠ¨ é’å°‘å¹´ æˆé•¿ è‹±æ–‡ å°è¯´ å®—æ•™ ä¸–ç•Œè§‚ å¤å…¸ å®¡ç¾ åŸåˆ™ è’²æŸ æ–‡å­¦æ‰¹è¯„ æ€æƒ³ æ´»åŠ¨ å•å…ƒ è¯æ±‡ ä½œä¸š ä»»åŠ¡ é©±åŠ¨ é˜…è¯» å¤è¿° èƒ½åŠ› è¯»è€… å‰§åœº ä¸­å­¦ç”Ÿ æœ—è¯» èƒ½åŠ› æœ—è¯» ä½“éªŒ äº’è”ç½‘ æ—¶ä»£ è·å– è¯æ±‡å­¦ çŸ¥è¯† æ–°é€”å¾„ åœ¨çº¿ è¯å…¸ ä¸­å°å­¦ è‹±è¯­æ•™å­¦ å¯ç¤º æƒ…å¢ƒ é«˜é˜¶ æ€ç»´ é˜…è¯»è¯¾ è¯»å æ´»åŠ¨ å•å…ƒ æ•´ä½“ è§†è§’ å†™ä½œ æ´»åŠ¨ æ·±åº¦ è¯»å†™ è¿‡ç¨‹ è¾“å‡º è¯­è¨€ æŠ€èƒ½ è¯„å§” ç‚¹è¯„ åè§‚ è®¤çŸ¥ æƒ…å†µ å…¨å›½ è¯¾å ‚æ•™å­¦ è§‚æ‘© åŸ¹è®­ è¯¾ä¸º ä¸ªæ¡ˆ æ´»åŠ¨ å¯¹è¯ æ•™å­¦ç­–ç•¥ äº”å¹´çº§ ä¸Šå†Œ ä¸»é¢˜ è¯­å¢ƒ å¼•é¢† è‹±è¯­è¯­æ³• ç ”ç‰ˆ æ ‡å‡† ç¬¬äºŒå†Œ ç¬¬å…­ å•å…ƒ æ¡ˆä¾‹ è‹±è¯­è¯¾å ‚ è§†é¢‘ æ¢è®¨
</pre></div>
</div>
</div>
</div>
<p>But even after applying the stopwords, I found that the results still had a few noisy or meaningless terms. So I manually removed a few more â€” kind of a second-round cleanup.</p>
</section>
<section id="word-frequency-counting">
<h2>4. Word frequency counting<a class="headerlink" href="#word-frequency-counting" title="Link to this heading">#</a></h2>
<p>Letâ€™s count the word frequency.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count the keyword frequency</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">processed_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="wordcloud-generating">
<h2>5. Wordcloud Generating<a class="headerlink" href="#wordcloud-generating" title="Link to this heading">#</a></h2>
<p>Custom the wordcloud picture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate wordcloud</span>
<span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span>
    <span class="n">font_path</span><span class="o">=</span><span class="s2">&quot;/System/Library/Fonts/Supplemental/Songti.ttc&quot;</span><span class="p">,</span>  
    <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>  <span class="c1"># background color</span>
    <span class="n">max_words</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>            <span class="c1"># The maximum number of words displayed</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>    <span class="c1"># The size of picture</span>
    <span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span>         <span class="c1"># color matching</span>
<span class="p">)</span>

<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">wc</span><span class="o">.</span><span class="n">generate_from_frequencies</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualisation">
<h2>6. Visualisation<a class="headerlink" href="#visualisation" title="Link to this heading">#</a></h2>
<p>Use matlotlib generate a picture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualise the wordcloud and import the picture.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">wordcloud</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s1">&#39;english_learning_wordcloud.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a12c789f2094a3c31a3a3d45d07b939395aaee4944a7f8610d9f0abd2bb781b7.png" src="_images/a12c789f2094a3c31a3a3d45d07b939395aaee4944a7f8610d9f0abd2bb781b7.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;wordcloud.wordcloud.WordCloud at 0x16fed7e90&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="analysis">
<h2>7. Analysis<a class="headerlink" href="#analysis" title="Link to this heading">#</a></h2>
<p>The word cloud generated from manuscript titles in English Language Learning highlights a clear thematic concentration on reading, thinking, writing, and classroom activity design. The most prominent term is é˜…è¯» (reading), indicating that reading instruction is a central concern of the journal. This focus is further supported by related terms such as è¯­ç¯‡ (text), è¯»å†™ (reading-writing), and è¯»åå†™ (post-reading writing), suggesting an integrated approach to reading and writing in the language learning process.</p>
<p>æ€ç»´ (thinking) appears frequently, reflecting an emphasis on the cultivation of critical and reflective thinking skills. This focus aligns with broader educational goals that aim to develop studentsâ€™ cognitive abilities and strategic learning approaches. Terms like ç­–ç•¥ (strategy), è·¯å¾„ (pathway), and åæ€ (reflection) further indicate an interest in thinking-driven teaching models and learning processes.</p>
<p>å†™ä½œ (writing) is another dominant theme, pointing to the importance of writing pedagogy and its integration with reading activities. The recurrence of terms such as ä»»åŠ¡ (task), è¾“å‡º (output), and ä½œæ–‡ (composition) suggests a task-based orientation that emphasizes writing as both a learning objective and a method for language output.</p>
<p>Classroom practice is a significant dimension of the submitted manuscripts, as seen in keywords like è¯¾å ‚ (classroom), æ´»åŠ¨ (activity), å®æ–½ (implementation), and æ•™å­¦ç­–ç•¥ (teaching strategies). These terms imply a strong emphasis on practical teaching, lesson design, and classroom engagement. Additional words such as å•å…ƒ (unit), é¡¹ç›® (project), and æ¨¡å¼ (model) point to structural considerations in curriculum design and innovative instructional formats.</p>
<p>Overall, the thematic focus of the journalâ€™s manuscripts reflects a strong commitment to reading-centered instruction, the integration of thinking and writing, and the development of effective and engaging classroom practices.</p>
</section>
<section id="a-small-side-quest-regional-word-cloud">
<h2>A small side questï¼šregional word cloudï¼<a class="headerlink" href="#a-small-side-quest-regional-word-cloud" title="Link to this heading">#</a></h2>
<p>While I was working on the title-based word cloud, I got curious â€” what if I looked at author affiliations or regions instead? Maybe that would reveal something interesting too.</p>
<p>So I made a small tweak in the code to switch the data source: instead of grabbing all the titles, I pulled in the â€œä½œè€…åœ°åŒºâ€ (author region) column and built a new corpus from that.</p>
<p>Of course, this required updating the stopword list again. This time I removed a different set of high-frequency but unhelpful words like â€œçœâ€ (province), â€œå¸‚â€ (city), â€œå¤§å­¦â€ (university), and similar generic location terms. I also filtered out empty entries and single-character tokens to keep things clean.</p>
<p>Then I used the same pipeline â€” segmentation, filtering, counting, word cloud generation â€” and it worked nicely.</p>
<p>The result? A word cloud that visually shows which regions or institutions appear most frequently. Not exactly deep analysis, but it was a fun side experiment and a good reminder that once the basic pipeline is built, you can reuse it flexibly for different types of text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;/Users/snowliu/Downloads/20250307170539.xls&quot;</span>

<span class="c1"># read Excel</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s2">&quot;ç¨¿ä»¶ä¿¡æ¯&quot;</span><span class="p">,</span><span class="n">header</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>


<span class="c1"># 2. Processing Chinese word segmentation</span>
<span class="k">def</span> <span class="nf">process_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># Custom stopword list</span>
    <span class="n">stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39;å¸‚&#39;</span><span class="p">,</span> <span class="s1">&#39;çœ&#39;</span><span class="p">,</span> <span class="s1">&#39;åŒº&#39;</span><span class="p">,</span> <span class="s1">&#39;æ•™è‚²&#39;</span><span class="p">,</span> <span class="s1">&#39;å‘å±•&#39;</span><span class="p">,</span> <span class="s1">&#39;ç¬¬&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸€&#39;</span><span class="p">,</span> <span class="s1">&#39;äºŒ&#39;</span><span class="p">,</span> <span class="s1">&#39;å·&#39;</span><span class="p">,</span><span class="s1">&#39;å­¦æ ¡&#39;</span><span class="p">,</span><span class="s1">&#39;ç¬¬ä¸€&#39;</span><span class="p">,</span><span class="s1">&#39;é™„å±ä¸­å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸­å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;å°å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;ç¬¬äºŒ&#39;</span><span class="p">,</span><span class="s1">&#39;å¤§å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸­å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸­å¿ƒå°å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;é™„å±&#39;</span><span class="p">,</span><span class="s1">&#39;æ•™å¸ˆ&#39;</span><span class="p">,</span><span class="s1">&#39;ç ”ç©¶é™¢&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸­å¿ƒ&#39;</span><span class="p">,</span><span class="s1">&#39;é«˜çº§ä¸­å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;åŒºæ™¯è‹‘&#39;</span><span class="p">,</span><span class="s1">&#39;åˆ†é™¢&#39;</span><span class="p">,</span><span class="s1">&#39;å¤–å›½è¯­&#39;</span><span class="p">,</span><span class="s1">&#39;è¿›ä¿®å­¦æ ¡&#39;</span><span class="p">,</span><span class="s1">&#39;ç¬¬ä¸‰&#39;</span><span class="p">,</span><span class="s1">&#39;å¸ˆèŒƒå¤§å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;å¸ˆå¤§é™„ä¸­&#39;</span><span class="p">,</span><span class="s1">&#39;ç§‘æŠ€&#39;</span><span class="p">,</span><span class="s1">&#39;ç ”ç©¶&#39;</span><span class="p">,</span><span class="s1">&#39;ç¬¬ä¸‰åä¹&#39;</span><span class="p">,</span><span class="s1">&#39;ä¸­æœ—æ‚¦&#39;</span><span class="p">,</span><span class="s1">&#39;é›†å›¢&#39;</span><span class="p">,</span><span class="s1">&#39;ç ”ç©¶æ‰€&#39;</span><span class="p">,</span><span class="s1">&#39;å†œæ‘&#39;</span><span class="p">,</span><span class="s1">&#39;é™ˆç»çº¶&#39;</span><span class="p">,</span><span class="s1">&#39;é˜³å…‰&#39;</span><span class="p">,</span><span class="s1">&#39;ç§‘å­¦&#39;</span><span class="p">,</span><span class="s1">&#39;é”¦ç»£&#39;</span><span class="p">,</span><span class="s1">&#39;å›½é™…&#39;</span><span class="p">,</span><span class="s1">&#39;ç¬¬ä¸ƒåä¹&#39;</span><span class="p">,</span><span class="s1">&#39;ä¿¡æ¯å·¥ç¨‹&#39;</span><span class="p">])</span>
   
    <span class="c1"># Use jieba for word segmentation</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
    
    <span class="c1"># Filter out stopwords and non-Chinese characters</span>
    <span class="n">filtered</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> 
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> 
           <span class="s1">&#39;</span><span class="se">\u4e00</span><span class="s1">&#39;</span> <span class="o">&lt;=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="s1">&#39;</span><span class="se">\u9fff</span><span class="s1">&#39;</span> <span class="ow">and</span> 
           <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered</span><span class="p">)</span>

<span class="c1"># 3. Generate corpus</span>
<span class="n">all_titles</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;åœ°åŒº&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">())</span>
<span class="n">processed_text</span> <span class="o">=</span> <span class="n">process_text</span><span class="p">(</span><span class="n">all_titles</span><span class="p">)</span>

<span class="c1"># 4. Count word frequency</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">processed_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="c1"># 5. Generate word cloud</span>
<span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span>
    <span class="n">font_path</span><span class="o">=</span><span class="s2">&quot;/System/Library/Fonts/Supplemental/Songti.ttc&quot;</span><span class="p">,</span>  
    <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>  
    <span class="n">max_words</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>            
    <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>   
    <span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span>        
<span class="p">)</span>

<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">wc</span><span class="o">.</span><span class="n">generate_from_frequencies</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span>

<span class="c1"># visualisation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">wordcloud</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s1">&#39;english_learning_wordcloud.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0fc61567bfb7759c9351c17ae2e439ea714e63865d95f9868bd9d964e9f2cebf.png" src="_images/0fc61567bfb7759c9351c17ae2e439ea714e63865d95f9868bd9d964e9f2cebf.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;wordcloud.wordcloud.WordCloud at 0x16d50fef0&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="conclusion">
<h2>8. Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>This project focuses on analysing the thematic trends of manuscripts published in the journal <em>English Language Learning</em> by applying natural language processing (NLP) techniques using Python. The manuscript titles, exported in Excel format from the editorial system, were first imported and processed using the <code class="docutils literal notranslate"><span class="pre">pandas</span></code> library. Chinese word segmentation was performed with the <code class="docutils literal notranslate"><span class="pre">jieba</span></code> package, and a custom stopword list was applied to remove common but semantically insignificant words, as well as non-Chinese characters, thereby enhancing the focus and clarity of the extracted keywords.</p>
<p>Following text processing, word frequency statistics were calculated using the <code class="docutils literal notranslate"><span class="pre">Counter</span></code> module. The <code class="docutils literal notranslate"><span class="pre">wordcloud</span></code> and <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> libraries were then used to visualize the results in the form of a word cloud. The visualization clearly highlights frequently occurring terms such as â€œé˜…è¯»â€ (reading), â€œæ€ç»´â€ (thinking), â€œå†™ä½œâ€ (writing), â€œè¯¾å ‚â€ (classroom), â€œæ´»åŠ¨â€ (activity), and â€œè¯­ç¯‡â€ (text/discourse), indicating that current research in the journal places a strong emphasis on reading instruction, cognitive development, writing pedagogy, and classroom-based practices. These findings not only reflect ongoing trends in language education research but also provide data-driven insights into the journalâ€™s topical orientation.</p>
<p>This project demonstrates the effective application of natural language processing in the analysis of educational text data. It offers an end-to-end pipeline from data import and preprocessing to statistical analysis and visualization. The method presented is scalable and adaptable, with the potential to be applied in other contexts such as tracking topic evolution, identifying research hotspots, and optimizing editorial strategies in academic publishing. As such, it contributes to the broader goal of promoting digital and intelligent approaches in education research.</p>
</section>
<section id="what-did-i-learn">
<h2>What did I learn?<a class="headerlink" href="#what-did-i-learn" title="Link to this heading">#</a></h2>
<p>Building this pipeline was actually straightforward, but deciding what to keep or discard (in text cleaning) took the most thought.
I now appreciate how useful a domain-specific stopword list is. Generic ones donâ€™t work well in educational contexts.
Visualization helps, but interpretation is key. A word cloud is just a starting point â€” I had to think about why certain words stood out and what they represented.
More personally:</p>
<p>I liked doing this kind of mini-project. It felt like a mix of editing, language analysis, and data work â€” all things I enjoy.
It gave me ideas for bigger things I might try next (e.g., topic modeling, cross-year comparisons, author-based trends).</p>
</section>
<section id="what-could-be-better">
<h2>What could be better?<a class="headerlink" href="#what-could-be-better" title="Link to this heading">#</a></h2>
<p>If I had more time, Iâ€™d love to:</p>
<p>Use TF-IDF instead of raw word counts (to highlight more unique terms)
Try topic modeling (like LDA) to see if articles cluster into different themes
Track keyword changes over time (like a mini â€œresearch trend reportâ€)
Alsoâ€¦ make the word cloud prettier. But thatâ€™s just me being picky.</p>
</section>
<section id="final-thought">
<h2>Final thought<a class="headerlink" href="#final-thought" title="Link to this heading">#</a></h2>
<p>This wasnâ€™t a big or fancy project, but it was honest and useful. I got to work with real data from my field, sharpen my Python skills, and reflect on whatâ€™s happening in English education research â€” all at once.</p>
<p>Sometimes thatâ€™s all you need: a small project, a real question, and a few good tools.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="notebooks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Content with notebooks</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-this-project-about">What is this project aboutï¼Ÿ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-did-i-do-it">Why did i do itï¼Ÿ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-tools-did-i-use">What tools did I useï¼Ÿ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-import">1. Data import</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing">2. Data processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-generating">3. Corpus Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-frequency-counting">4. Word frequency counting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wordcloud-generating">5. Wordcloud Generating</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisation">6. Visualisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">7. Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-small-side-quest-regional-word-cloud">A small side questï¼šregional word cloudï¼</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">8. Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-i-learn">What did I learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-could-be-better">What could be better?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-thought">Final thought</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>